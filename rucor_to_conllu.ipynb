{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RuCor to CoNLL-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpuscula import Conllu\n",
    "import csv\n",
    "import difflib\n",
    "import os\n",
    "import pandas as pd\n",
    "#import random\n",
    "import re\n",
    "#import textdistance\n",
    "from toxine import TextPreprocessor\n",
    "#from uuid import uuid4\n",
    "\n",
    "#text_dist = textdistance.JaroWinkler().distance\n",
    "\n",
    "#random.seed(42)  # for uuid\n",
    "\n",
    "dataset_dir = '../_dataset'\n",
    "rucor_dir = os.path.join(dataset_dir, 'rucoref')\n",
    "conllu_dir = os.path.join(dataset_dir, 'rucoref_conllu')\n",
    "\n",
    "models_dir = '..'              # workaround for *mordl*: models should be\n",
    "models_root_dir = '_models'    # placed in the ../_models/ directory\n",
    "# if you don't have cdict, set cdict_path = None\n",
    "cdict_path = os.path.join(models_dir, models_root_dir, 'upos-bert_model/cdict.pickle')\n",
    "\n",
    "log_fn = os.path.join(dataset_dir, 'out.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fit corpus dict... "
     ]
    }
   ],
   "source": [
    "TAG_COREF_HEADS = False\n",
    "\n",
    "if TAG_COREF_HEADS:\n",
    "    from mordl import UposTagger, FeatsTagger, LemmaTagger\n",
    "\n",
    "    _work_dir = os.path.abspath(os.getcwd())\n",
    "    os.chdir(models_dir)\n",
    "    tagger_u = UposTagger()\n",
    "    tagger_u.load(os.path.join(models_root_dir, 'upos-bert_model'), device='cuda:0', dataset_device='cuda:0')\n",
    "    tagger_f = FeatsTagger()\n",
    "    tagger_f.load(os.path.join(models_root_dir, 'feats-bert_model'), device='cuda:0', dataset_device='cuda:0')\n",
    "    #tagger_l = LemmaTagger()\n",
    "    #tagger_l.load(os.path.join(models_root_dir, 'lemma-ft_model'), device='cuda:0', dataset_device='cuda:0')\n",
    "    os.chdir(_work_dir)\n",
    "tp = TextPreprocessor(cdict_restore_from=cdict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rucor_docs_fn = os.path.join(rucor_dir, 'Documents.txt')\n",
    "rucor_groups_fn = os.path.join(rucor_dir, 'Groups.txt')\n",
    "rucor_tokens_fn = os.path.join(rucor_dir, 'Tokens.txt')\n",
    "\n",
    "docs = pd.read_csv(rucor_docs_fn, sep='\\t', index_col='doc_id', quoting=csv.QUOTE_NONE)\n",
    "groups = pd.read_csv(rucor_groups_fn, sep='\\t', index_col='group_id', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# process certain doc\n",
    "DOC_ID = 0\n",
    "# adjust correct shifts to the wrong ones in Rucor\n",
    "NEED_SHIFT_ADJUST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(conllu_dir):\n",
    "    os.mkdir(conllu_dir, mode=0o755)\n",
    "\n",
    "def get_fns(doc_id, conllu_dir=None):\n",
    "    in_fn_ = docs.loc[doc_id, 'path']\n",
    "    in_fn = os.path.join(rucor_dir, 'rucoref_texts', in_fn_)\n",
    "    if conllu_dir:\n",
    "        out_dir = os.path.join(conllu_dir, os.path.dirname(in_fn_))\n",
    "        if not os.path.isdir(out_dir):\n",
    "            os.mkdir(out_dir, mode=0o755)\n",
    "    else:\n",
    "        out_dir = dataset_dir\n",
    "    out_fn_ = os.path.join(out_dir, os.path.splitext(os.path.basename(in_fn))[0])\n",
    "    out_ext_ = '.conllu'\n",
    "    out_fn = out_fn_ + out_ext_\n",
    "    return in_fn, out_fn\n",
    "\n",
    "if DOC_ID:\n",
    "    in_fn, out_fn = get_fns(DOC_ID)\n",
    "    print(in_fn, out_fn, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_punct(punct):\n",
    "    return punct.replace('—', '-').replace(';', '.').replace('...', '.').replace('…', '.') \\\n",
    "                .replace('«', '\"').replace('„', '\"') \\\n",
    "                .replace('»', '\"').replace('“', '\"') \\\n",
    "                .replace('``', '\"').replace(\"''\", '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw(in_fn):\n",
    "    re_html = re.compile('&[a-z]+;')\n",
    "\n",
    "    with open(in_fn, 'rb') as f:\n",
    "        raw = f.read().decode('utf-8-sig').lower()\n",
    "\n",
    "        def process(match):\n",
    "            text = match.group(0)\n",
    "            len_text = len(text)\n",
    "            text = tp._unescape_html(text)\n",
    "            return ' ' * (len_text - len(text)) + text\n",
    "\n",
    "        raw = re_html.sub(process, raw)\n",
    "\n",
    "        raw_forms, raw_punct = [], []\n",
    "        isalnum = None\n",
    "        for ch in raw:\n",
    "            res = ch.isalnum()\n",
    "            if res:\n",
    "                if res != isalnum:\n",
    "                    raw_forms.append(ch)\n",
    "                else:\n",
    "                    raw_forms[-1] += ch\n",
    "            elif not ch.isspace():\n",
    "                raw_punct.append(ch)\n",
    "            isalnum = res\n",
    "\n",
    "        raw_forms_ids = []\n",
    "        idx = 0\n",
    "        for token in raw_forms:\n",
    "            idx_ = raw.index(token, idx)\n",
    "            raw_forms_ids.append(idx_)\n",
    "            idx = idx_ + len(token)\n",
    "        idx = 0\n",
    "        raw_punct_ids = []\n",
    "        for i, ch in enumerate(raw_punct):\n",
    "            idx_ = raw.index(ch, idx)\n",
    "            raw_punct_ids.append(idx_)\n",
    "            raw_punct[i] = norm_punct(ch)\n",
    "            idx = idx_ + 1\n",
    "\n",
    "    return list(zip(raw_forms, raw_forms_ids)), list(zip(raw_punct, raw_punct_ids))\n",
    "\n",
    "if DOC_ID:\n",
    "    raw_corpus, raw_puncts = get_raw(in_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust correct shifts to the wrong ones in Rucor\n",
    "def adjust_raw_corpus(doc_id, raw_corpus):\n",
    "    for i, (form, idx) in enumerate(raw_corpus):\n",
    "        if doc_id == 115:\n",
    "            if idx >= 1288:\n",
    "                raw_corpus[i] = form, idx + 2\n",
    "            elif idx >= 771:\n",
    "                raw_corpus[i] = form, idx + 1\n",
    "        elif doc_id == 116:\n",
    "            if idx >= 1545:\n",
    "                raw_corpus[i] = form, idx + 7\n",
    "            elif idx >= 884:\n",
    "                raw_corpus[i] = form, idx + 6\n",
    "            elif idx >= 858:\n",
    "                raw_corpus[i] = form, idx + 5\n",
    "            elif idx >= 394:\n",
    "                raw_corpus[i] = form, idx + 4\n",
    "            elif idx >= 388:\n",
    "                raw_corpus[i] = form, idx + 3\n",
    "            elif idx >= 386:\n",
    "                raw_corpus[i] = form, idx + 2\n",
    "            elif idx >= 165:\n",
    "                raw_corpus[i] = form, idx + 1\n",
    "\n",
    "if DOC_ID and NEED_SHIFT_ADJUST:\n",
    "    adjust_raw_corpus(DOC_ID, raw_corpus)\n",
    "    adjust_raw_corpus(DOC_ID, raw_puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    tp.clear_corpus()\n",
    "    tp.load_pars(in_fn, eop=r'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    tp.do_all(tag_date=False, norm_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    _ = tp.save(out_fn + ('$' if TAG_COREF_HEADS else ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID and TAG_COREF_HEADS:\n",
    "    tagger_f.predict(tagger_u.predict(out_fn + '$'), save_to=out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID and TAG_COREF_HEADS:\n",
    "    os.remove(out_fn + '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_nonalnum = re.compile('(?:\\W|_)+')\n",
    "re_alnum = re.compile('(?:[^\\W_])+')\n",
    "\n",
    "if DOC_ID:\n",
    "    corpus_orig = list(Conllu.load(out_fn))\n",
    "    corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus():\n",
    "    tag_shortcut = tp.TAG_SHORTCUT[2:]\n",
    "    masks = list(x[1:] for x in tp.TAG_MASKS.keys())\n",
    "    for sent in corpus_orig:\n",
    "        for tok in sent[0]:\n",
    "            form, misc = tok['FORM'], tok['MISC']\n",
    "            for misc_ in misc:\n",
    "                if misc_ in masks:\n",
    "                    form = misc[misc_]\n",
    "                elif misc_ == tag_shortcut:\n",
    "                    form = misc[misc_]\n",
    "            corpus.append((re_nonalnum.sub('', form.lower()), misc, tok['UPOS'],\n",
    "                           re_alnum.sub('', form)))\n",
    "\n",
    "if DOC_ID:\n",
    "    make_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_corpus():\n",
    "    corpus_, raw_corpus_ = re_nonalnum.sub('', ''.join(x[0] for x in corpus)), \\\n",
    "                           ''.join(x[0] for x in raw_corpus)\n",
    "    if corpus_ != raw_corpus_:\n",
    "        print('                CORPUS_:')\n",
    "        print(corpus_)\n",
    "        print('                RAW_CORPUS_:')\n",
    "        print(raw_corpus_)\n",
    "        raise ValueError('The corpus is not the same as the raw corpus!')\n",
    "\n",
    "if DOC_ID:\n",
    "    validate_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(corpus, raw_corpus):\n",
    "\n",
    "    len_corpus, len_raw_corpus = len(corpus), len(raw_corpus)\n",
    "\n",
    "    def find_next(i, j):\n",
    "        form, misc = corpus[i][:2]\n",
    "        if not form:\n",
    "            return i + 1, j\n",
    "\n",
    "        raw_form, raw_form_idx = raw_corpus[j]\n",
    "        form_, raw_form_ = form, raw_form\n",
    "        len_form, len_raw_form = len(form), len(raw_form)\n",
    "\n",
    "        misc['Shift'] = str(raw_form_idx)\n",
    "\n",
    "        i_, j_ = i + 1, j + 1\n",
    "        if len_form < len_raw_form:\n",
    "            while i_ < len_corpus and len(form_) < len_raw_form:\n",
    "                form_ += corpus[i_][0]\n",
    "                i_ += 1\n",
    "            form = form_\n",
    "        elif len_form > len_raw_form:\n",
    "            while j_ < len_raw_corpus and len(raw_form_) < len_form:\n",
    "                raw_form_ += raw_corpus[j_][0]\n",
    "                j_ += 1\n",
    "            raw_form = raw_form_\n",
    "\n",
    "        if form != raw_form:\n",
    "            raise ValueError('form [{}] is not equal to raw_form [{}]!'.format(form, raw_form))\n",
    "\n",
    "        return i_, j_,\n",
    "\n",
    "    mid_ = {'mid': 0}\n",
    "    def get_mention_id():\n",
    "        #mid = uuid.uuid4()\n",
    "        mid_['mid'] += 1\n",
    "        mid = mid_['mid']\n",
    "        return str(mid)\n",
    "\n",
    "    i = j = 0\n",
    "    while i < len_corpus:\n",
    "        i_, j_ = find_next(i, j)\n",
    "        for ii in range(i, i_):  # TODO\n",
    "            form, misc, upos = corpus[ii][:3]\n",
    "            if TAG_COREF_HEADS and upos in ['NOUN', 'PRON', 'PROPN']:\n",
    "                misc['Coref_' + get_mention_id()] = 'Head'\n",
    "        i, j = i_, j_\n",
    "\n",
    "if DOC_ID:\n",
    "    process_corpus(corpus, raw_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_puncts(corpus, raw_puncts):\n",
    "\n",
    "    sm = difflib.SequenceMatcher()\n",
    "    len_corpus, len_raw_puncts = len(corpus), len(raw_puncts)\n",
    "\n",
    "    def find_next(i, j):\n",
    "        start = stop = 0\n",
    "        for i in range(i, len_corpus):\n",
    "            form, misc = corpus[i][:2]\n",
    "            if not form:\n",
    "                break\n",
    "            shift = misc.get('Shift')\n",
    "            if shift:\n",
    "                start = int(shift)\n",
    "        puncts, miscs = [], []\n",
    "        for i_ in range(i, len_corpus):\n",
    "            form, misc, _, punct = corpus[i_]\n",
    "            if form:\n",
    "                shift = misc.get('Shift')\n",
    "                if shift:\n",
    "                    stop = int(shift)\n",
    "                    break\n",
    "            else:\n",
    "                puncts.append(norm_punct(punct))\n",
    "                miscs.append(misc)\n",
    "        if not stop:\n",
    "            return len_corpus, j\n",
    "\n",
    "        for j in range(j, len_raw_puncts):\n",
    "            if raw_puncts[j][1] >= start:\n",
    "                break\n",
    "        for j_ in range(j, len_raw_puncts):\n",
    "            if raw_puncts[j_][1] >= stop:\n",
    "                break\n",
    "        if j_ == j:\n",
    "            i_, j_ = len_corpus, len_raw_puncts\n",
    "        raws, shifts = zip(*raw_puncts[j:j_])\n",
    "        for ir in range(len(raws) - 3):\n",
    "            if raws[ir:ir + 3] == ('.',) * 3:\n",
    "                raws = raws[:ir + 1] + ('', '') + raws[ir + 3:]\n",
    "\n",
    "        sm.set_seqs(puncts, raws)\n",
    "        matches = sm.get_matching_blocks()\n",
    "        for a, b, size in matches:\n",
    "            for k in range(size):\n",
    "                miscs[a + k]['Shift'] = str(shifts[b + k])\n",
    "\n",
    "        return i_, j_,\n",
    "\n",
    "    i = j = 0\n",
    "    while i < len_corpus:\n",
    "        i, j = find_next(i, j)\n",
    "\n",
    "if DOC_ID:\n",
    "    process_puncts(corpus, raw_puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    for sent in corpus_orig:\n",
    "        for tok in sent[0]:\n",
    "            print('{:20s}{}'.format(tok['FORM'] or '', tok['MISC'].get('Shift', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    shifts = {}\n",
    "    for sent in corpus_orig:\n",
    "        for tok in sent[0]:\n",
    "            form, misc = tok['FORM'] or '', tok['MISC']\n",
    "            shift = misc.get('Shift', '')\n",
    "            if shift:\n",
    "                shifts[shift] = (norm_punct(form), misc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    raw_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    raw_puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    for group_id, chain_id, link, tks, tk_shifts, attrs, hd_shift in \\\n",
    "        groups[groups['doc_id'] == DOC_ID].reset_index() \\\n",
    "              [['group_id', 'chain_id', 'link',\n",
    "                'content', 'tk_shifts', 'attributes', 'hd_shifts']].values:\n",
    "        tks = tks.split()\n",
    "        tk_shifts = tk_shifts.split(',')\n",
    "        attrs = [(x for x in x.split(':')) for x in attrs.split('|')] \\\n",
    "                    if not pd.isnull(attrs) else \\\n",
    "                []\n",
    "        assert len(tks) == len(tk_shifts), \\\n",
    "            'len({}) != len({})'.format(tks, tk_shifts)\n",
    "        for tk, tk_shift in zip(tks, tk_shifts):\n",
    "            form, misc = shifts.get(tk_shift, (None, None))\n",
    "            if form is None:\n",
    "                print('token {} ({}) is not found'.format(tk_shift, tk))\n",
    "            elif norm_punct(form) != norm_punct(tk):\n",
    "                print('token {}: {} != {}'.format(tk_shift, form, tk))\n",
    "            else:\n",
    "                misc['RuCor_group_id'] = str(group_id)\n",
    "                misc['RuCor_chain_id'] = str(chain_id)\n",
    "                if len(tks) == 1 or hd_shift == tk_shift:\n",
    "                    misc['RuCor_link_id'] = str(link)\n",
    "                    for attr, val in attrs:\n",
    "                        misc['RuCor_attrs_' + attr] = val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    Conllu.save(corpus_orig, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(log_fn, 'wt', encoding='utf-8') as f_log:\n",
    "\n",
    "    def log(text=''):\n",
    "        print(text)\n",
    "        print(text, file=f_log)\n",
    "\n",
    "    for doc_id in groups['doc_id'].unique():\n",
    "        in_fn, out_fn = get_fns(doc_id, conllu_dir=conllu_dir)\n",
    "        log('{}: {}'.format(doc_id, in_fn))\n",
    "\n",
    "        raw_corpus, raw_puncts = get_raw(in_fn)\n",
    "        if NEED_SHIFT_ADJUST:\n",
    "            adjust_raw_corpus(doc_id, raw_corpus)\n",
    "            adjust_raw_corpus(doc_id, raw_puncts)\n",
    "\n",
    "        tp.clear_corpus()\n",
    "        tp.load_pars(in_fn, eop=r'\\n')\n",
    "        tp.do_all(tag_date=False, norm_punct=True)\n",
    "        tp.save(out_fn + ('$' if TAG_COREF_HEADS else ''))\n",
    "\n",
    "        if TAG_COREF_HEADS:\n",
    "            tagger_f.predict(tagger_u.predict(out_fn + '$'), save_to=out_fn)\n",
    "\n",
    "        corpus_orig = list(Conllu.load(out_fn))\n",
    "        corpus = []\n",
    "        make_corpus()\n",
    "        validate_corpus()\n",
    "        process_corpus(corpus, raw_corpus)\n",
    "        process_puncts(corpus, raw_puncts)\n",
    "\n",
    "        shifts = {}\n",
    "        for sent in corpus_orig:\n",
    "            for tok in sent[0]:\n",
    "                form, misc = tok['FORM'] or '', tok['MISC']\n",
    "                shift = misc.get('Shift', '')\n",
    "                if shift:\n",
    "                    shifts[shift] = (norm_punct(form), misc)\n",
    "        for group_id, chain_id, link, tks, tk_shifts, attrs, hd_shift in \\\n",
    "            groups[groups['doc_id'] == doc_id].reset_index() \\\n",
    "                  [['group_id', 'chain_id', 'link',\n",
    "                    'content', 'tk_shifts', 'attributes', 'hd_shifts']].values:\n",
    "            tks = tks.split()\n",
    "            tk_shifts = tk_shifts.split(',')\n",
    "            attrs = [(x for x in x.split(':')) for x in attrs.split('|')] \\\n",
    "                        if not pd.isnull(attrs) else \\\n",
    "                    []\n",
    "            assert len(tks) == len(tk_shifts), \\\n",
    "                'len({}) != len({})'.format(tks, tk_shifts)\n",
    "            for tk, tk_shift in zip(tks, tk_shifts):\n",
    "                form, misc = shifts.get(tk_shift, (None, None))\n",
    "                if form is None:\n",
    "                    print('token {} ({}) is not found'.format(tk_shift, tk))\n",
    "                    log('token {} ({}) is not found'.format(tk_shift, tk))\n",
    "                elif norm_punct(form) != norm_punct(tk):\n",
    "                    print('token {}: {} != {}'.format(tk_shift, form, tk))\n",
    "                    log('token {}: {} != {}'.format(tk_shift, form, tk))\n",
    "                else:\n",
    "                    misc['RuCor_group_id'] = str(group_id)\n",
    "                    misc['RuCor_chain_id'] = str(chain_id)\n",
    "                    if len(tks) == 1 or hd_shift == tk_shift:\n",
    "                        misc['RuCor_link_id'] = str(link)\n",
    "                        for attr, val in attrs:\n",
    "                            misc['RuCor_attrs_' + attr] = val\n",
    "\n",
    "        log()\n",
    "        Conllu.save(corpus_orig, out_fn)\n",
    "\n",
    "    if TAG_COREF_HEADS:\n",
    "        os.remove(out_fn + '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
