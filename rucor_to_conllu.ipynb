{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RuCor to CoNLL-U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1102 19:16:35.927671 139753066800960 wrapper.py:16] Loading dictionaries from /usr/local/lib/python3.6/dist-packages/pymorphy2_dicts/data\n",
      "I1102 19:16:35.952976 139753066800960 wrapper.py:20] format: 2.4, revision: 393442, updated: 2015-01-17T16:03:56.586168\n"
     ]
    }
   ],
   "source": [
    "from corpuscula import Conllu\n",
    "import csv\n",
    "import difflib\n",
    "import junky\n",
    "from mordl import UposTagger, FeatsTagger, LemmaTagger\n",
    "import os\n",
    "import pandas as pd\n",
    "#import random\n",
    "import re\n",
    "import textdistance\n",
    "from toxine import TextPreprocessor\n",
    "#from uuid import uuid4\n",
    "\n",
    "#text_dist = textdistance.JaroWinkler().distance\n",
    "\n",
    "#random.seed(42)  # for uuid\n",
    "\n",
    "cdict_path = os.path.join('_models/upos-bert_model/cdict.pickle')\n",
    "\n",
    "dataset_dir = '_dataset'\n",
    "rucor_dir = os.path.join(dataset_dir, 'rucoref')\n",
    "rucor_docs_fn = os.path.join(rucor_dir, 'Documents.txt')\n",
    "rucor_groups_fn = os.path.join(rucor_dir, 'Groups.txt')\n",
    "rucor_tokens_fn = os.path.join(rucor_dir, 'Tokens.txt')\n",
    "\n",
    "log_fn = os.path.join(dataset_dir, 'out.log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset... done.\n",
      "Creating model... done.\n",
      "Loading state_dict... done.\n",
      "Fit corpus dict... done.\n",
      "Loading dataset... done.\n",
      "Creating model... done.\n",
      "Loading state_dict... done.\n",
      "Fit corpus dict... done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fit corpus dict... done.\n"
     ]
    }
   ],
   "source": [
    "tagger_u = UposTagger()\n",
    "tagger_u.load('_models/upos-bert_model', device='cuda:0', dataset_device='cuda:0')\n",
    "tagger_f = FeatsTagger()\n",
    "tagger_f.load('_models/feats-bert_model', device='cuda:0', dataset_device='cuda:0')\n",
    "#tagger_l = LemmaTagger()\n",
    "#tagger_l.load('_models/lemma-ft_model', device='cuda:0', dataset_device='cuda:0')\n",
    "tp = TextPreprocessor(cdict_restore_from=cdict_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = pd.read_csv(rucor_docs_fn, sep='\\t', index_col='doc_id', quoting=csv.QUOTE_NONE)\n",
    "groups = pd.read_csv(rucor_groups_fn, sep='\\t', index_col='group_id', quoting=csv.QUOTE_NONE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DOC_ID = 0\n",
    "TAG_COREF_HEADS = False\n",
    "NEED_SHIFT_ADJUST = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fns(doc_id):\n",
    "    in_fn = os.path.join(rucor_dir, 'rucoref_texts', docs.loc[doc_id, 'path'])\n",
    "    out_fn_ = os.path.join(dataset_dir, os.path.splitext(os.path.basename(in_fn))[0])\n",
    "    out_ext_ = '.conllu'\n",
    "    out_fn = out_fn_ + out_ext_\n",
    "    return in_fn, out_fn\n",
    "\n",
    "if DOC_ID:\n",
    "    in_fn, out_fn = get_fns(DOC_ID)\n",
    "    print(in_fn, out_fn, sep=', ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm_punct(punct):\n",
    "    return punct.replace('—', '-').replace(';', '.').replace('...', '.').replace('…', '.') \\\n",
    "                .replace('«', '\"').replace('„', '\"') \\\n",
    "                .replace('»', '\"').replace('“', '\"') \\\n",
    "                .replace('``', '\"').replace(\"''\", '\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_raw(in_fn):\n",
    "    re_html = re.compile('&[a-z]+;')\n",
    "\n",
    "    with open(in_fn, 'rb') as f:\n",
    "        raw = f.read().decode('utf-8-sig').lower()\n",
    "\n",
    "        def process(match):\n",
    "            text = match.group(0)\n",
    "            len_text = len(text)\n",
    "            text = tp._unescape_html(text)\n",
    "            return ' ' * (len_text - len(text)) + text\n",
    "\n",
    "        raw = re_html.sub(process, raw)\n",
    "\n",
    "        raw_forms, raw_punct = [], []\n",
    "        isalnum = None\n",
    "        for ch in raw:\n",
    "            res = ch.isalnum()\n",
    "            if res:\n",
    "                if res != isalnum:\n",
    "                    raw_forms.append(ch)\n",
    "                else:\n",
    "                    raw_forms[-1] += ch\n",
    "            elif not ch.isspace():\n",
    "                raw_punct.append(ch)\n",
    "            isalnum = res\n",
    "\n",
    "        raw_forms_ids = []\n",
    "        idx = 0\n",
    "        for token in raw_forms:\n",
    "            idx_ = raw.index(token, idx)\n",
    "            raw_forms_ids.append(idx_)\n",
    "            idx = idx_ + len(token)\n",
    "        idx = 0\n",
    "        raw_punct_ids = []\n",
    "        for i, ch in enumerate(raw_punct):\n",
    "            idx_ = raw.index(ch, idx)\n",
    "            raw_punct_ids.append(idx_)\n",
    "            raw_punct[i] = norm_punct(ch)\n",
    "            idx = idx_ + 1\n",
    "\n",
    "    return list(zip(raw_forms, raw_forms_ids)), list(zip(raw_punct, raw_punct_ids))\n",
    "\n",
    "if DOC_ID:\n",
    "    raw_corpus, raw_puncts = get_raw(in_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust correct shifts to the wrong ones in Rucor\n",
    "def adjust_raw_corpus(doc_id, raw_corpus):\n",
    "    for i, (form, idx) in enumerate(raw_corpus):\n",
    "        if doc_id == 115:\n",
    "            if idx >= 1288:\n",
    "                raw_corpus[i] = form, idx + 2\n",
    "            elif idx >= 771:\n",
    "                raw_corpus[i] = form, idx + 1\n",
    "        elif doc_id == 116:\n",
    "            if idx >= 1545:\n",
    "                raw_corpus[i] = form, idx + 7\n",
    "            elif idx >= 884:\n",
    "                raw_corpus[i] = form, idx + 6\n",
    "            elif idx >= 858:\n",
    "                raw_corpus[i] = form, idx + 5\n",
    "            elif idx >= 394:\n",
    "                raw_corpus[i] = form, idx + 4\n",
    "            elif idx >= 388:\n",
    "                raw_corpus[i] = form, idx + 3\n",
    "            elif idx >= 386:\n",
    "                raw_corpus[i] = form, idx + 2\n",
    "            elif idx >= 165:\n",
    "                raw_corpus[i] = form, idx + 1\n",
    "\n",
    "if DOC_ID and NEED_SHIFT_ADJUST:\n",
    "    adjust_raw_corpus(DOC_ID, raw_corpus)\n",
    "    adjust_raw_corpus(DOC_ID, raw_puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    tp.clear_corpus()\n",
    "    tp.load_pars(in_fn, eop=r'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    tp.do_all(tag_date=False, norm_punct=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    _ = tp.save(out_fn + '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    _ = tagger_f.predict(tagger_u.predict(out_fn + '$'), save_to=out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    os.remove(out_fn + '$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "re_nonalnum = re.compile('(?:\\W|_)+')\n",
    "re_alnum = re.compile('(?:[^\\W_])+')\n",
    "\n",
    "if DOC_ID:\n",
    "    corpus_orig = list(Conllu.load(out_fn))\n",
    "    corpus = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_corpus():\n",
    "    tag_shortcut = tp.TAG_SHORTCUT[2:]\n",
    "    masks = list(x[1:] for x in tp.TAG_MASKS.keys())\n",
    "    for sent in corpus_orig:\n",
    "        for tok in sent[0]:\n",
    "            form, misc = tok['FORM'], tok['MISC']\n",
    "            for misc_ in misc:\n",
    "                if misc_ in masks:\n",
    "                    form = misc[misc_]\n",
    "                elif misc_ == tag_shortcut:\n",
    "                    form = misc[misc_]\n",
    "            corpus.append((re_nonalnum.sub('', form.lower()), misc, tok['UPOS'],\n",
    "                           re_alnum.sub('', form)))\n",
    "\n",
    "if DOC_ID:\n",
    "    make_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_corpus():\n",
    "    corpus_, raw_corpus_ = re_nonalnum.sub('', ''.join(x[0] for x in corpus)), \\\n",
    "                           ''.join(x[0] for x in raw_corpus)\n",
    "    if corpus_ != raw_corpus_:\n",
    "        print('                CORPUS_:')\n",
    "        print(corpus_)\n",
    "        print('                RAW_CORPUS_:')\n",
    "        print(raw_corpus_)\n",
    "        raise ValueError('The corpus is not the same as the raw corpus!')\n",
    "\n",
    "if DOC_ID:\n",
    "    validate_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_corpus(corpus, raw_corpus):\n",
    "\n",
    "    len_corpus, len_raw_corpus = len(corpus), len(raw_corpus)\n",
    "\n",
    "    def find_next(i, j):\n",
    "        form, misc = corpus[i][:2]\n",
    "        if not form:\n",
    "            return i + 1, j\n",
    "\n",
    "        raw_form, raw_form_idx = raw_corpus[j]\n",
    "        form_, raw_form_ = form, raw_form\n",
    "        len_form, len_raw_form = len(form), len(raw_form)\n",
    "\n",
    "        misc['Shift'] = str(raw_form_idx)\n",
    "\n",
    "        i_, j_ = i + 1, j + 1\n",
    "        if len_form < len_raw_form:\n",
    "            while i_ < len_corpus and len(form_) < len_raw_form:\n",
    "                form_ += corpus[i_][0]\n",
    "                i_ += 1\n",
    "            form = form_\n",
    "        elif len_form > len_raw_form:\n",
    "            while j_ < len_raw_corpus and len(raw_form_) < len_form:\n",
    "                raw_form_ += raw_corpus[j_][0]\n",
    "                j_ += 1\n",
    "            raw_form = raw_form_\n",
    "\n",
    "        if form != raw_form:\n",
    "            raise ValueError('form [{}] is not equal to raw_form [{}]!'.format(form, raw_form))\n",
    "\n",
    "        return i_, j_,\n",
    "\n",
    "    mid_ = {'mid': 0}\n",
    "    def get_mention_id():\n",
    "        #mid = uuid.uuid4()\n",
    "        mid_['mid'] += 1\n",
    "        mid = mid_['mid']\n",
    "        return str(mid)\n",
    "\n",
    "    i = j = 0\n",
    "    while i < len_corpus:\n",
    "        i_, j_ = find_next(i, j)\n",
    "        for ii in range(i, i_):  # TODO\n",
    "            form, misc, upos = corpus[ii][:3]\n",
    "            if TAG_COREF_HEADS and upos in ['NOUN', 'PRON', 'PROPN']:\n",
    "                misc['Coref_' + get_mention_id()] = 'Head'\n",
    "        i, j = i_, j_\n",
    "\n",
    "if DOC_ID:\n",
    "    process_corpus(corpus, raw_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_puncts(corpus, raw_puncts):\n",
    "\n",
    "    sm = difflib.SequenceMatcher()\n",
    "    len_corpus, len_raw_puncts = len(corpus), len(raw_puncts)\n",
    "\n",
    "    def find_next(i, j):\n",
    "        start = stop = 0\n",
    "        for i in range(i, len_corpus):\n",
    "            form, misc = corpus[i][:2]\n",
    "            if not form:\n",
    "                break\n",
    "            shift = misc.get('Shift')\n",
    "            if shift:\n",
    "                start = int(shift)\n",
    "        puncts, miscs = [], []\n",
    "        for i_ in range(i, len_corpus):\n",
    "            form, misc, _, punct = corpus[i_]\n",
    "            if form:\n",
    "                shift = misc.get('Shift')\n",
    "                if shift:\n",
    "                    stop = int(shift)\n",
    "                    break\n",
    "            else:\n",
    "                puncts.append(norm_punct(punct))\n",
    "                miscs.append(misc)\n",
    "        if not stop:\n",
    "            return len_corpus, j\n",
    "\n",
    "        for j in range(j, len_raw_puncts):\n",
    "            if raw_puncts[j][1] >= start:\n",
    "                break\n",
    "        for j_ in range(j, len_raw_puncts):\n",
    "            if raw_puncts[j_][1] >= stop:\n",
    "                break\n",
    "        if j_ == j:\n",
    "            i_, j_ = len_corpus, len_raw_puncts\n",
    "        raws, shifts = zip(*raw_puncts[j:j_])\n",
    "        for ir in range(len(raws) - 3):\n",
    "            if raws[ir:ir + 3] == ('.',) * 3:\n",
    "                raws = raws[:ir + 1] + ('', '') + raws[ir + 3:]\n",
    "\n",
    "        sm.set_seqs(puncts, raws)\n",
    "        matches = sm.get_matching_blocks()\n",
    "        for a, b, size in matches:\n",
    "            for k in range(size):\n",
    "                miscs[a + k]['Shift'] = str(shifts[b + k])\n",
    "\n",
    "        return i_, j_,\n",
    "\n",
    "    i = j = 0\n",
    "    while i < len_corpus:\n",
    "        i, j = find_next(i, j)\n",
    "\n",
    "if DOC_ID:\n",
    "    process_puncts(corpus, raw_puncts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    Conllu.save(corpus_orig, out_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    corpus = list(Conllu.load(out_fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    for sent in corpus:\n",
    "        for tok in sent[0]:\n",
    "            print('{:20s}{}'.format(tok['FORM'] or '', tok['MISC'].get('Shift', '')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    shifts = {}\n",
    "    for sent in corpus:\n",
    "        for tok in sent[0]:\n",
    "            form, shift = tok['FORM'] or '', tok['MISC'].get('Shift', '')\n",
    "            if shift:\n",
    "                shifts[shift] = norm_punct(form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    raw_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    raw_puncts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DOC_ID:\n",
    "    for tks, tk_shifts in groups[groups['doc_id'] == DOC_ID][['content', 'tk_shifts']].values:\n",
    "        tks = tks.split()\n",
    "        tk_shifts = tk_shifts.split(',')\n",
    "        assert len(tks) == len(tk_shifts), \\\n",
    "            'len({}) != len({})'.format(tks, tk_shifts)\n",
    "        for tk, tk_shift in zip(tks, tk_shifts):\n",
    "            tok = shifts.get(tk_shift)\n",
    "            if tok is None:\n",
    "                print('token {} ({}) is not found'.format(tk_shift, tk))\n",
    "            elif norm_punct(tok) != norm_punct(tk):\n",
    "                print('token {}: {} != {}'.format(tk_shift, tok, tk))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: _dataset/rucoref/rucoref_texts/fiction/102_beliajev_nad_bezdnoj.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 70                                                           \n",
      "Corpus has been loaded: 70 sentences, 957 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/70 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 70                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 70 sentences, 957 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 70                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:00<00:00, 181.87it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 70/70 [00:00<00:00, 206.04it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 70                                                           \n",
      "Corpus has been loaded: 70 sentences, 957 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 70                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 70                                                           \n",
      "Corpus has been loaded: 70 sentences, 957 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 4827: вас != вас,\n",
      "token 4827: вас != вас,\n",
      "token 4849: он != он,\n",
      "token 4849: он != он,\n",
      "\n",
      "2: _dataset/rucoref/rucoref_texts/fiction/107_dragunsky_volshebnaja_sila_iskusstva.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 137                                                           \n",
      "Corpus has been loaded: 137 sentences, 1120 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/137 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 137                                                           \n",
      "Corpus has been processed: 1 documents, 41 paragraphs, 137 sentences, 1120 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 137                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 137/137 [00:00<00:00, 317.77it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 137/137 [00:00<00:00, 319.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 137                                                           \n",
      "Corpus has been loaded: 137 sentences, 1120 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 137                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 137                                                           \n",
      "Corpus has been loaded: 137 sentences, 1120 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 3767: Альбертик-то != Альбертик\n",
      "token 3767: Альбертик-то != Альбертик\n",
      "token 3776 (-) is not found\n",
      "token 3776 (-) is not found\n",
      "token 3777 (то) is not found\n",
      "token 3777 (то) is not found\n",
      "token 4096: Альбертиком-то != Альбертиком\n",
      "token 4096: Альбертиком-то != Альбертиком\n",
      "token 4107 (-) is not found\n",
      "token 4107 (-) is not found\n",
      "token 4108 (то) is not found\n",
      "token 4108 (то) is not found\n",
      "token 5081: какой-то != какой\n",
      "token 5081: какой-то != какой\n",
      "token 5086 (-) is not found\n",
      "token 5086 (-) is not found\n",
      "token 5087 (то) is not found\n",
      "token 5087 (то) is not found\n",
      "\n",
      "3: _dataset/rucoref/rucoref_texts/fiction/15_paustovsky_zhilcy_starogo_doma.txt\n",
      "Load corpus\n",
      "[=] 54                                                           \n",
      "Corpus has been loaded: 54 sentences, 862 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 54/54 [00:00<00:00, 428962.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been processed: 1 documents, 21 paragraphs, 54 sentences, 862 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 54/54 [00:00<00:00, 364135.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been loaded: 54 sentences, 862 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been loaded: 54 sentences, 862 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "5: _dataset/rucoref/rucoref_texts/fiction/2_astafiev_zhizn_prozhit.txt\n",
      "Load corpus\n",
      "[=] 44                                                           \n",
      "Corpus has been loaded: 44 sentences, 1104 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 44/44 [00:00<00:00, 351522.62it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been processed: 1 documents, 8 paragraphs, 44 sentences, 1104 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 44/44 [00:00<00:00, 347550.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been loaded: 44 sentences, 1104 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been loaded: 44 sentences, 1104 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "6: _dataset/rucoref/rucoref_texts/fiction/30_dojl_sluchaj.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 135                                                           \n",
      "Corpus has been loaded: 135 sentences, 2022 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/135 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 135                                                           \n",
      "Corpus has been processed: 1 documents, 49 paragraphs, 135 sentences, 2022 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 135                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 135/135 [00:00<00:00, 145.13it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 135/135 [00:00<00:00, 143.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 135                                                           \n",
      "Corpus has been loaded: 135 sentences, 2022 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 135                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 135                                                           \n",
      "Corpus has been loaded: 135 sentences, 2022 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "7: _dataset/rucoref/rucoref_texts/fiction/34_kassil_solnce_svetit.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 96                                                           \n",
      "Corpus has been loaded: 96 sentences, 1502 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/96 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 96                                                           \n",
      "Corpus has been processed: 1 documents, 40 paragraphs, 96 sentences, 1502 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 96                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 96/96 [00:00<00:00, 205.64it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 96/96 [00:00<00:00, 204.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 96                                                           \n",
      "Corpus has been loaded: 96 sentences, 1502 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 96                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 96                                                           \n",
      "Corpus has been loaded: 96 sentences, 1502 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 631: какой-то != какой\n",
      "token 631: какой-то != какой\n",
      "token 636 (-) is not found\n",
      "token 636 (-) is not found\n",
      "token 637 (то) is not found\n",
      "token 637 (то) is not found\n",
      "\n",
      "8: _dataset/rucoref/rucoref_texts/fiction/43_musatov_stozhary.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 111                                                           \n",
      "Corpus has been loaded: 111 sentences, 1414 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/111 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 111                                                           \n",
      "Corpus has been processed: 1 documents, 59 paragraphs, 111 sentences, 1414 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 111                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 111/111 [00:00<00:00, 318.98it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 111/111 [00:00<00:00, 315.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 111                                                           \n",
      "Corpus has been loaded: 111 sentences, 1414 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 111                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 111                                                           \n",
      "Corpus has been loaded: 111 sentences, 1414 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "9: _dataset/rucoref/rucoref_texts/fiction/44_nagibin_siren.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 172                                                           \n",
      "Corpus has been loaded: 172 sentences, 3099 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/172 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 172                                                           \n",
      "Corpus has been processed: 1 documents, 33 paragraphs, 172 sentences, 3099 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 172                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 172/172 [00:00<00:00, 199.71it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 172/172 [00:00<00:00, 198.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 172                                                           \n",
      "Corpus has been loaded: 172 sentences, 3099 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 172                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 172                                                           \n",
      "Corpus has been loaded: 172 sentences, 3099 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "10: _dataset/rucoref/rucoref_texts/fiction/53_beliajev_dom_s_prividenijami.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 130                                                           \n",
      "Corpus has been loaded: 130 sentences, 1554 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/130 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 130                                                           \n",
      "Corpus has been processed: 1 documents, 53 paragraphs, 130 sentences, 1554 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 130                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 130/130 [00:00<00:00, 215.21it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 130/130 [00:00<00:00, 219.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 130                                                           \n",
      "Corpus has been loaded: 130 sentences, 1554 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 130                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 130                                                           \n",
      "Corpus has been loaded: 130 sentences, 1554 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "11: _dataset/rucoref/rucoref_texts/fiction/5_petrushevskaya_v_detstve.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 85                                                           \n",
      "Corpus has been loaded: 85 sentences, 897 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/85 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 85                                                           \n",
      "Corpus has been processed: 1 documents, 30 paragraphs, 85 sentences, 897 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 85                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 85/85 [00:00<00:00, 223.50it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 85/85 [00:00<00:00, 223.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 85                                                           \n",
      "Corpus has been loaded: 85 sentences, 897 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 85                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 85                                                           \n",
      "Corpus has been loaded: 85 sentences, 897 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 2798: младше-классника != младше\n",
      "token 2798: младше-классника != младше\n",
      "token 2804 (-) is not found\n",
      "token 2804 (-) is not found\n",
      "token 2805 (классника) is not found\n",
      "token 2805 (классника) is not found\n",
      "\n",
      "12: _dataset/rucoref/rucoref_texts/fiction/67_zamiatin_kolumb.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 73                                                           \n",
      "Corpus has been loaded: 73 sentences, 883 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/73 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 73                                                           \n",
      "Corpus has been processed: 1 documents, 31 paragraphs, 73 sentences, 883 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 73                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 73/73 [00:00<00:00, 233.00it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 73/73 [00:00<00:00, 237.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 73                                                           \n",
      "Corpus has been loaded: 73 sentences, 883 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 73                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 73                                                           \n",
      "Corpus has been loaded: 73 sentences, 883 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "13: _dataset/rucoref/rucoref_texts/fiction/73_ilf_schastlivy_otec.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 874 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been processed: 1 documents, 52 paragraphs, 103 sentences, 874 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 435.93it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 103/103 [00:00<00:00, 430.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 874 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 874 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 3205: т. != т\n",
      "token 3205: т. != т\n",
      "token 3206 (.) is not found\n",
      "token 3206 (.) is not found\n",
      "token 3205: т. != т\n",
      "token 3205: т. != т\n",
      "token 3206 (.) is not found\n",
      "token 3206 (.) is not found\n",
      "token 3926: Сундучанский-отец != Сундучанский\n",
      "token 3926: Сундучанский-отец != Сундучанский\n",
      "token 3938 (-) is not found\n",
      "token 3938 (-) is not found\n",
      "token 3939 (отец) is not found\n",
      "token 3939 (отец) is not found\n",
      "\n",
      "15: _dataset/rucoref/rucoref_texts/fiction/andersen_motylek.txt\n",
      "Load corpus\n",
      "[=] 75                                                           \n",
      "Corpus has been loaded: 75 sentences, 751 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/75 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 75                                                           \n",
      "Corpus has been processed: 1 documents, 28 paragraphs, 75 sentences, 751 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 75                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75/75 [00:00<00:00, 189.80it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 75/75 [00:00<00:00, 191.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 75                                                           \n",
      "Corpus has been loaded: 75 sentences, 751 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 75                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 75                                                           \n",
      "Corpus has been loaded: 75 sentences, 751 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "16: _dataset/rucoref/rucoref_texts/fiction/bazhov_travyanaja_zapadenka.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been loaded: 71 sentences, 735 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/71 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been processed: 1 documents, 20 paragraphs, 71 sentences, 735 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 326.63it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 71/71 [00:00<00:00, 327.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been loaded: 71 sentences, 735 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been loaded: 71 sentences, 735 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "17: _dataset/rucoref/rucoref_texts/fiction/bunin_skazka.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 94                                                           \n",
      "Corpus has been loaded: 94 sentences, 1510 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/94 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 94                                                           \n",
      "Corpus has been processed: 1 documents, 20 paragraphs, 94 sentences, 1510 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 94                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 94/94 [00:00<00:00, 199.96it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 94/94 [00:00<00:00, 197.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 94                                                           \n",
      "Corpus has been loaded: 94 sentences, 1510 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 94                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 94                                                           \n",
      "Corpus has been loaded: 94 sentences, 1510 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 3335: такой-то != такой\n",
      "token 3335: такой-то != такой\n",
      "token 3340 (-) is not found\n",
      "token 3340 (-) is not found\n",
      "token 3341 (то) is not found\n",
      "token 3341 (то) is not found\n",
      "\n",
      "18: _dataset/rucoref/rucoref_texts/fiction/dostojevskij_podrostok.txt\n",
      "Load corpus\n",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 667 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 99949.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been processed: 1 documents, 3 paragraphs, 28 sentences, 667 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 283672.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 667 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 667 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "19: _dataset/rucoref/rucoref_texts/fiction/dovlatov_kompromiss_6.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 113                                                           \n",
      "Corpus has been loaded: 113 sentences, 957 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/113 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 113                                                           \n",
      "Corpus has been processed: 1 documents, 32 paragraphs, 113 sentences, 957 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 113                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 113/113 [00:00<00:00, 249.06it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 113/113 [00:00<00:00, 244.40it/s]\n",
      "token 167: Л. != Л\n",
      "token 167: Л. != Л\n",
      "token 168 (.) is not found\n",
      "token 168 (.) is not found\n",
      "\n",
      "20: _dataset/rucoref/rucoref_texts/fiction/fet_knyaginya.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 113                                                           \n",
      "Corpus has been loaded: 113 sentences, 957 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 113                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 113                                                           \n",
      "Corpus has been loaded: 113 sentences, 957 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 126                                                           \n",
      "Corpus has been loaded: 126 sentences, 1850 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/126 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 126                                                           \n",
      "Corpus has been processed: 1 documents, 36 paragraphs, 126 sentences, 1850 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 126                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 126/126 [00:00<00:00, 247.45it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 126/126 [00:00<00:00, 248.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 126                                                           \n",
      "Corpus has been loaded: 126 sentences, 1850 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 126                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 126                                                           \n",
      "Corpus has been loaded: 126 sentences, 1850 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 9261: каким-то != каким\n",
      "token 9261: каким-то != каким\n",
      "token 9266 (-) is not found\n",
      "token 9266 (-) is not found\n",
      "token 9267 (то) is not found\n",
      "token 9267 (то) is not found\n",
      "\n",
      "21: _dataset/rucoref/rucoref_texts/fiction/gilyarovskij_moi_skitanija.txt\n",
      "Load corpus\n",
      "[=] 63                                                           \n",
      "Corpus has been loaded: 63 sentences, 1333 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 63/63 [00:00<00:00, 159662.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been processed: 1 documents, 19 paragraphs, 63 sentences, 1333 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 63/63 [00:00<00:00, 533820.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been loaded: 63 sentences, 1333 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been loaded: 63 sentences, 1333 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 2774: Н. != Н\n",
      "token 2774: Н. != Н\n",
      "token 2775 (.) is not found\n",
      "token 2775 (.) is not found\n",
      "token 2777: Д. != Д\n",
      "token 2777: Д. != Д\n",
      "token 2778 (.) is not found\n",
      "token 2778 (.) is not found\n",
      "\n",
      "22: _dataset/rucoref/rucoref_texts/fiction/gogol_zapiski_3.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 87                                                           \n",
      "Corpus has been loaded: 87 sentences, 1201 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 87                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 87 sentences, 1201 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 87                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 87/87 [00:00<00:00, 288.78it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 87/87 [00:00<00:00, 289.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 87                                                           \n",
      "Corpus has been loaded: 87 sentences, 1201 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 87                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 87                                                           \n",
      "Corpus has been loaded: 87 sentences, 1201 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "23: _dataset/rucoref/rucoref_texts/fiction/harms_upadanije.txt\n",
      "Load corpus\n",
      "[=] 26                                                           \n",
      "Corpus has been loaded: 26 sentences, 405 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 26/26 [00:00<00:00, 234520.22it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 26/26 [00:00<00:00, 269263.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 26 sentences, 405 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been loaded: 26 sentences, 405 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been loaded: 26 sentences, 405 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "24: _dataset/rucoref/rucoref_texts/fiction/korolenko_mgnovenije.txt\n",
      "Load corpus\n",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 632 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 234412.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been processed: 1 documents, 10 paragraphs, 28 sentences, 632 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 251478.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 632 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 632 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 315: Хозе-Мигуэль != Хозе\n",
      "token 315: Хозе-Мигуэль != Хозе\n",
      "token 320 (Мигуэль) is not found\n",
      "token 320 (Мигуэль) is not found\n",
      "token 327 (-) is not found\n",
      "token 327 (-) is not found\n",
      "token 2006: Мигуэль-Хозе != Мигуэль\n",
      "token 2006: Мигуэль-Хозе != Мигуэль\n",
      "token 2014 (Хозе) is not found\n",
      "token 2014 (Хозе) is not found\n",
      "token 2018 (-) is not found\n",
      "token 2018 (-) is not found\n",
      "\n",
      "28: _dataset/rucoref/rucoref_texts/fiction/turgenev_veshnije_vody.txt\n",
      "Load corpus\n",
      "[=] 53                                                           \n",
      "Corpus has been loaded: 53 sentences, 1199 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 53/53 [00:00<00:00, 197422.83it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 53 sentences, 1199 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 53/53 [00:00<00:00, 132162.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been loaded: 53 sentences, 1199 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been loaded: 53 sentences, 1199 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1693: госпожа != г\n",
      "token 1693: госпожа != г\n",
      "token 1694 (-) is not found\n",
      "token 1694 (-) is not found\n",
      "token 1695 (жа) is not found\n",
      "token 1695 (жа) is not found\n",
      "\n",
      "30: _dataset/rucoref/rucoref_texts/Lenta/2013_04_11_dotless_.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 382 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 269441.37it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 279620.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 30 sentences, 382 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 382 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 382 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1251: cloud.blog != cloud\n",
      "token 1251: cloud.blog != cloud\n",
      "token 1256 (,) is not found\n",
      "token 1256 (,) is not found\n",
      "token 1258 (.) is not found\n",
      "token 1258 (.) is not found\n",
      "token 1259 (blog) is not found\n",
      "token 1259 (blog) is not found\n",
      "\n",
      "41: _dataset/rucoref/rucoref_texts/Lenta/2013_07_31_krebs_.txt\n",
      "Load corpus\n",
      "[=] 26                                                           \n",
      "Corpus has been loaded: 26 sentences, 481 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 26/26 [00:00<00:00, 56474.32it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 26/26 [00:00<00:00, 118663.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 26 sentences, 481 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been loaded: 26 sentences, 481 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 26                                                           \n",
      "Corpus has been loaded: 26 sentences, 481 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "51: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-01-19-cutshort.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 435 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 42550.91it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 14 sentences, 435 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 104857.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 435 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 435 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "52: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-01-24-if.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 356 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 57136.03it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 63946.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 8 paragraphs, 22 sentences, 356 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 356 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 356 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 2: Ивано-Франковске != Ивано\n",
      "token 2: Ивано-Франковске != Ивано\n",
      "token 7 (-) is not found\n",
      "token 7 (-) is not found\n",
      "token 8 (Франковске) is not found\n",
      "token 8 (Франковске) is not found\n",
      "\n",
      "53: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-01-30-crimea.txt\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 272 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 40970.00it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 92820.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 16 sentences, 272 tokens\n",
      "Save corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 272 tokens\n",
      "Save corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 272 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "54: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-02-03-capitanic.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 279 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 20061.58it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 136241.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 14 sentences, 279 tokens\n",
      "Save corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 279 tokens\n",
      "Save corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 279 tokens\n",
      "Load corpus... done.\n",
      "Preprocess corpus\n",
      "[> 0                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 0: Премьер-министр != Премьер\n",
      "token 0: Премьер-министр != Премьер\n",
      "token 7 (-) is not found\n",
      "token 7 (-) is not found\n",
      "token 8 (министр) is not found\n",
      "token 8 (министр) is not found\n",
      "token 477: Премьер-министр != Премьер\n",
      "token 477: Премьер-министр != Премьер\n",
      "token 484 (-) is not found\n",
      "token 484 (-) is not found\n",
      "token 485 (министр) is not found\n",
      "token 485 (министр) is not found\n",
      "\n",
      "55: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-02-03-london.txt\n",
      "Load corpus\n",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 489 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 36035.75it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[=] 28                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 28 sentences, 489 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 96818.23it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 489 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 489 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "56: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-02-03-name1.txt\n",
      "Load corpus\n",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 359 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 23/23 [00:00<00:00, 102083.59it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 23/23 [00:00<00:00, 96856.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 23 sentences, 359 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 359 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 359 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "57: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-02-03-rucksack.txt\n",
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 282 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 55874.39it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 41610.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 15 sentences, 282 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 282 tokens\n",
      "Save corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 282 tokens\n",
      "Load corpus... done.\n",
      "Preprocess corpus\n",
      "[=] 21                                                           \n",
      "Corpus has been processed: 1 documents, 8 paragraphs, 21 sentences, 389 tokens\n",
      "Save corpus\n",
      "[=] 21                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "58: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-02-04-party.txt\n",
      "Load corpus\n",
      "[=] 21                                                           \n",
      "Corpus has been loaded: 21 sentences, 389 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 21/21 [00:00<00:00, 16248.00it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 21/21 [00:00<00:00, 25814.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 21                                                           \n",
      "Corpus has been loaded: 21 sentences, 389 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 21                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 21                                                           \n",
      "Corpus has been loaded: 21 sentences, 389 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "59: _dataset/rucoref/rucoref_texts/Lenta/lenta.ru-news-2014-02-04-pyramid.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 404 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 68351.62it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 194262.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 22 sentences, 404 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 404 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 404 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "60: _dataset/rucoref/rucoref_texts/OpenCorpora/448-done.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 738 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 80401.99it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 11 paragraphs, 30 sentences, 738 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 272948.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 738 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 738 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 149: Нью-Йорка != Нью\n",
      "token 149: Нью-Йорка != Нью\n",
      "token 152 (-) is not found\n",
      "token 152 (-) is not found\n",
      "token 153 (Йорка) is not found\n",
      "token 153 (Йорка) is not found\n",
      "token 616: 16-летняя != 16\n",
      "token 616: 16-летняя != 16\n",
      "token 618 (-) is not found\n",
      "token 618 (-) is not found\n",
      "token 619 (летняя) is not found\n",
      "token 619 (летняя) is not found\n",
      "token 638: 74-летняя != 74\n",
      "token 638: 74-летняя != 74\n",
      "token 640 (-) is not found\n",
      "token 640 (-) is not found\n",
      "token 641 (летняя) is not found\n",
      "token 641 (летняя) is not found\n",
      "token 1720: Бут. != Бут\n",
      "token 1720: Бут. != Бут\n",
      "token 2718: Нью-Йорке != Нью\n",
      "token 2718: Нью-Йорке != Нью\n",
      "token 2721 (-) is not found\n",
      "token 2721 (-) is not found\n",
      "token 2722 (Йорке) is not found\n",
      "token 2722 (Йорке) is not found\n",
      "token 3054: Нью-Йорка != Нью\n",
      "token 3054: Нью-Йорка != Нью\n",
      "token 3057 (-) is not found\n",
      "token 3057 (-) is not found\n",
      "token 3058 (Йорка) is not found\n",
      "token 3058 (Йорка) is not found\n",
      "token 3538: 43-летнему != 43\n",
      "token 3538: 43-летнему != 43\n",
      "token 3540 (-) is not found\n",
      "token 3540 (-) is not found\n",
      "token 3541 (летнему) is not found\n",
      "token 3541 (летнему) is not found\n",
      "\n",
      "61: _dataset/rucoref/rucoref_texts/OpenCorpora/516-done.txt\n",
      "Load corpus\n",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 403 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 199728.76it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 99864.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been processed: 1 documents, 3 paragraphs, 24 sentences, 403 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 403 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 403 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "62: _dataset/rucoref/rucoref_texts/OpenCorpora/540-done.txt\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 271 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 87154.37it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 89717.73it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 16 sentences, 271 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 271 tokens\n",
      "Save corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 271 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "63: _dataset/rucoref/rucoref_texts/OpenCorpora/554-done.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 612 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 28813.63it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 17 paragraphs, 30 sentences, 612 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 100824.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 612 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 612 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "64: _dataset/rucoref/rucoref_texts/OpenCorpora/559-done.txt\n",
      "Load corpus\n",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 312 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 157055.44it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 168964.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 17 sentences, 312 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 312 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 312 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1547:  != Zülch\n",
      "token 1547:  != Zülch\n",
      "\n",
      "65: _dataset/rucoref/rucoref_texts/OpenCorpora/675-done.txt\n",
      "Load corpus\n",
      "[=] 33                                                           \n",
      "Corpus has been loaded: 33 sentences, 669 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 33/33 [00:00<00:00, 278495.03it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 33 sentences, 669 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 33/33 [00:00<00:00, 111174.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been loaded: 33 sentences, 669 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been loaded: 33 sentences, 669 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "66: _dataset/rucoref/rucoref_texts/OpenCorpora/682-done.txt\n",
      "Load corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 393 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 165130.08it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 113821.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 20 sentences, 393 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 393 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 393 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 96: 65-летия != 65\n",
      "token 96: 65-летия != 65\n",
      "token 98 (-) is not found\n",
      "token 98 (-) is not found\n",
      "token 99 (летия) is not found\n",
      "token 99 (летия) is not found\n",
      "token 1116: премьер-министра != премьер\n",
      "token 1116: премьер-министра != премьер\n",
      "token 1123 (-) is not found\n",
      "token 1123 (-) is not found\n",
      "token 1124 (министра) is not found\n",
      "token 1124 (министра) is not found\n",
      "\n",
      "67: _dataset/rucoref/rucoref_texts/OpenCorpora/689-done.txt\n",
      "Load corpus\n",
      "[=] 31                                                           \n",
      "Corpus has been loaded: 31 sentences, 669 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 31/31 [00:00<00:00, 266441.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 31                                                           \n",
      "Corpus has been processed: 1 documents, 11 paragraphs, 31 sentences, 669 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 31                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 31/31 [00:00<00:00, 98130.89it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 31                                                           \n",
      "Corpus has been loaded: 31 sentences, 669 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 31                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 31                                                           \n",
      "Corpus has been loaded: 31 sentences, 669 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1942: господина != г\n",
      "token 1942: господина != г\n",
      "token 1943 (-) is not found\n",
      "token 1943 (-) is not found\n",
      "token 1944 (на) is not found\n",
      "token 1944 (на) is not found\n",
      "token 1942: господина != г\n",
      "token 1942: господина != г\n",
      "token 1943 (-) is not found\n",
      "token 1943 (-) is not found\n",
      "token 1944 (на) is not found\n",
      "token 1944 (на) is not found\n",
      "token 2819: господине != г\n",
      "token 2819: господине != г\n",
      "token 2820 (-) is not found\n",
      "token 2820 (-) is not found\n",
      "token 2821 (не) is not found\n",
      "token 2821 (не) is not found\n",
      "token 2975: санкт-петербургской != санкт\n",
      "token 2975: санкт-петербургской != санкт\n",
      "token 2980 (-) is not found\n",
      "token 2980 (-) is not found\n",
      "token 2981 (петербургской) is not found\n",
      "token 2981 (петербургской) is not found\n",
      "\n",
      "68: _dataset/rucoref/rucoref_texts/OpenCorpora/789-done.txt\n",
      "Load corpus\n",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 552 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 23/23 [00:00<00:00, 53445.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 23 sentences, 552 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 23/23 [00:00<00:00, 213426.97it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 552 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 552 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 236: Нью-Йорке != Нью\n",
      "token 236: Нью-Йорке != Нью\n",
      "token 239 (-) is not found\n",
      "token 239 (-) is not found\n",
      "token 240 (Йорке) is not found\n",
      "token 240 (Йорке) is not found\n",
      "token 3266: Нью-Йорке != Нью\n",
      "token 3266: Нью-Йорке != Нью\n",
      "token 3269 (-) is not found\n",
      "token 3269 (-) is not found\n",
      "token 3270 (Йорке) is not found\n",
      "token 3270 (Йорке) is not found\n",
      "\n",
      "69: _dataset/rucoref/rucoref_texts/OpenCorpora/833-done.txt\n",
      "Load corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 344 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 64182.16it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 109655.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 20 sentences, 344 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 344 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 344 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 815 (—) is not found\n",
      "token 815 (—) is not found\n",
      "\n",
      "70: _dataset/rucoref/rucoref_texts/OpenCorpora/842-done.txt\n",
      "Load corpus\n",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 296 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 10/10 [00:00<00:00, 42842.74it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 10/10 [00:00<00:00, 106454.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been processed: 1 documents, 3 paragraphs, 10 sentences, 296 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 296 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 296 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 494: Уголовно-процессуальному != Уголовно\n",
      "token 494: Уголовно-процессуальному != Уголовно\n",
      "token 502 (-) is not found\n",
      "token 502 (-) is not found\n",
      "token 503 (процессуальному) is not found\n",
      "token 503 (процессуальному) is not found\n",
      "token 494: Уголовно-процессуальному != Уголовно\n",
      "token 494: Уголовно-процессуальному != Уголовно\n",
      "token 502 (-) is not found\n",
      "token 502 (-) is not found\n",
      "token 503 (процессуальному) is not found\n",
      "token 503 (процессуальному) is not found\n",
      "token 776: М. != М\n",
      "token 776: М. != М\n",
      "token 777 (.) is not found\n",
      "token 777 (.) is not found\n",
      "token 1085: М. != М\n",
      "token 1085: М. != М\n",
      "token 1086 (.) is not found\n",
      "token 1086 (.) is not found\n",
      "\n",
      "71: _dataset/rucoref/rucoref_texts/OpenCorpora/850-done.txt\n",
      "Load corpus\n",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 488 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 25/25 [00:00<00:00, 53939.09it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 25/25 [00:00<00:00, 90238.90it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 25 sentences, 488 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 488 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 488 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 51: 93-летний != 93\n",
      "token 51: 93-летний != 93\n",
      "token 53 (-) is not found\n",
      "token 53 (-) is not found\n",
      "token 54 (летний) is not found\n",
      "token 54 (летний) is not found\n",
      "\n",
      "72: _dataset/rucoref/rucoref_texts/OpenCorpora/870-done.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been processed: 1 documents, 17 paragraphs, 53 sentences, 720 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 53                                                           \n",
      "Corpus has been loaded: 53 sentences, 720 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 53/53 [00:00<00:00, 223190.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 53/53 [00:00<00:00, 456464.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been loaded: 53 sentences, 720 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 53                                                           \n",
      "Corpus has been loaded: 53 sentences, 720 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 160: муж. != муж\n",
      "token 160: муж. != муж\n",
      "token 695: по-видимому != по\n",
      "token 695: по-видимому != по\n",
      "token 697 (-) is not found\n",
      "token 697 (-) is not found\n",
      "token 698 (видимому) is not found\n",
      "token 698 (видимому) is not found\n",
      "\n",
      "73: _dataset/rucoref/rucoref_texts/OpenCorpora/890-done.txt\n",
      "Load corpus\n",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 348 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 142321.69it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 82910.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 17 sentences, 348 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 348 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 348 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "74: _dataset/rucoref/rucoref_texts/OpenCorpora/895-done.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 308 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 59724.72it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 92182.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 22 sentences, 308 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 308 tokens\n",
      "Save corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 308 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "75: _dataset/rucoref/rucoref_texts/OpenCorpora/908-done.txt\n",
      "Load corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 267 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 13/13 [00:00<00:00, 60316.32it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 13/13 [00:00<00:00, 117260.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 13 sentences, 267 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 267 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 267 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "76: _dataset/rucoref/rucoref_texts/OpenCorpora/921-done.txt\n",
      "Load corpus\n",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 830 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 49/49 [00:00<00:00, 114241.74it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been processed: 1 documents, 34 paragraphs, 49 sentences, 830 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 49/49 [00:00<00:00, 174170.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 830 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 830 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "77: _dataset/rucoref/rucoref_texts/OpenCorpora/992-done.txt\n",
      "Load corpus\n",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 831 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 269068.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 34 sentences, 831 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 96813.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 831 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 831 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "78: _dataset/rucoref/rucoref_texts/Science/09Jan2014_bloomberg_sleep.html.txt\n",
      "Load corpus\n",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 449 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 56236.48it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 99273.47it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 24 sentences, 449 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 449 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 449 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 434: Э. != Э.Чейслер\n",
      "token 434: Э. != Э.Чейслер\n",
      "token 2533: Э. != Э.Гринфилд\n",
      "token 2533: Э. != Э.Гринфилд\n",
      "\n",
      "80: _dataset/rucoref/rucoref_texts/fiction/strugackije_ponedelnik.txt\n",
      "Load corpus\n",
      "[=] 54                                                           \n",
      "Corpus has been loaded: 54 sentences, 757 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 54/54 [00:00<00:00, 272554.05it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been processed: 1 documents, 3 paragraphs, 54 sentences, 757 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 54/54 [00:00<00:00, 152622.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been loaded: 54 sentences, 757 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 54                                                           \n",
      "Corpus has been loaded: 54 sentences, 757 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "81: _dataset/rucoref/rucoref_texts/News/2009-abbas5_ru.txt\n",
      "Load corpus\n",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 872 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 37/37 [00:00<00:00, 323310.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 37 sentences, 872 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 37/37 [00:00<00:00, 254408.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 872 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 872 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 217: индо-пакистанское != индо\n",
      "token 217: индо-пакистанское != индо\n",
      "token 221 (-) is not found\n",
      "token 221 (-) is not found\n",
      "token 222 (пакистанское) is not found\n",
      "token 222 (пакистанское) is not found\n",
      "token 2237: 1960-х != 1960\n",
      "token 2237: 1960-х != 1960\n",
      "token 2241 (-) is not found\n",
      "token 2241 (-) is not found\n",
      "token 2242 (х) is not found\n",
      "token 2242 (х) is not found\n",
      "token 2246: 1970-х != 1970\n",
      "token 2246: 1970-х != 1970\n",
      "token 2250 (-) is not found\n",
      "token 2250 (-) is not found\n",
      "token 2251 (х) is not found\n",
      "token 2251 (х) is not found\n",
      "token 2679: Лашкар-и != Лашкар\n",
      "token 2679: Лашкар-и != Лашкар\n",
      "token 2686 (и) is not found\n",
      "token 2686 (и) is not found\n",
      "token 2687 (-) is not found\n",
      "token 2687 (-) is not found\n",
      "token 3452: Джамаат-уд != Джамаат\n",
      "token 3452: Джамаат-уд != Джамаат\n",
      "token 3460 (уд) is not found\n",
      "token 3460 (уд) is not found\n",
      "token 3462 (-) is not found\n",
      "token 3462 (-) is not found\n",
      "token 4166: \"Мы != Мы\n",
      "token 4166: \"Мы != Мы\n",
      "\n",
      "82: _dataset/rucoref/rucoref_texts/News/2009-abbas6_ru.txt\n",
      "Load corpus\n",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 870 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 365109.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been processed: 1 documents, 13 paragraphs, 41 sentences, 870 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 125066.52it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 870 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 870 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1130: Северо-западной != Северо\n",
      "token 1130: Северо-западной != Северо\n",
      "token 1136 (-) is not found\n",
      "token 1136 (-) is not found\n",
      "token 1137 (западной) is not found\n",
      "token 1137 (западной) is not found\n",
      "\n",
      "83: _dataset/rucoref/rucoref_texts/News/2009-abbas7_ru.txt\n",
      "Load corpus\n",
      "[=] 38                                                           \n",
      "Corpus has been loaded: 38 sentences, 769 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 38/38 [00:00<00:00, 332049.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been processed: 1 documents, 13 paragraphs, 38 sentences, 769 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 38/38 [00:00<00:00, 314987.26it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been loaded: 38 sentences, 769 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been loaded: 38 sentences, 769 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 656: Rah-e != Rah\n",
      "token 656: Rah-e != Rah\n",
      "token 659 (-) is not found\n",
      "token 659 (-) is not found\n",
      "token 660 (e) is not found\n",
      "token 660 (e) is not found\n",
      "token 661 (-) is not found\n",
      "token 661 (-) is not found\n",
      "token 662: -Nijat != Nijat\n",
      "token 662: -Nijat != Nijat\n",
      "\n",
      "84: _dataset/rucoref/rucoref_texts/News/2009-abusada7_ru.txt\n",
      "Load corpus\n",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 865 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 42/42 [00:00<00:00, 211477.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 42 sentences, 865 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 42/42 [00:00<00:00, 108607.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 865 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 865 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 674: Аль-Каиды != Аль\n",
      "token 674: Аль-Каиды != Аль\n",
      "token 677 (-) is not found\n",
      "token 677 (-) is not found\n",
      "token 678 (Каиды) is not found\n",
      "token 678 (Каиды) is not found\n",
      "token 1652: Аль-Каиды != Аль\n",
      "token 1652: Аль-Каиды != Аль\n",
      "token 1655 (-) is not found\n",
      "token 1655 (-) is not found\n",
      "token 1656 (Каиды) is not found\n",
      "token 1656 (Каиды) is not found\n",
      "token 1964: Аль-Каиды != Аль\n",
      "token 1964: Аль-Каиды != Аль\n",
      "token 1967 (-) is not found\n",
      "token 1967 (-) is not found\n",
      "token 1968 (Каиды) is not found\n",
      "token 1968 (Каиды) is not found\n",
      "token 2090: Аль-Каиды != Аль\n",
      "token 2090: Аль-Каиды != Аль\n",
      "token 2093 (-) is not found\n",
      "token 2093 (-) is not found\n",
      "token 2094 (Каиды) is not found\n",
      "token 2094 (Каиды) is not found\n",
      "token 2861: Аль-Каидой != Аль\n",
      "token 2861: Аль-Каидой != Аль\n",
      "token 2864 (-) is not found\n",
      "token 2864 (-) is not found\n",
      "token 2865 (Каидой) is not found\n",
      "token 2865 (Каидой) is not found\n",
      "token 3272: Аль-Каиды != Аль\n",
      "token 3272: Аль-Каиды != Аль\n",
      "token 3275 (-) is not found\n",
      "token 3275 (-) is not found\n",
      "token 3276 (Каиды) is not found\n",
      "token 3276 (Каиды) is not found\n",
      "\n",
      "85: _dataset/rucoref/rucoref_texts/News/2009-ahtisaari3_ru.txt\n",
      "Load corpus\n",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 694 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 86544.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been processed: 1 documents, 10 paragraphs, 28 sentences, 694 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 28/28 [00:00<00:00, 223270.94it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 694 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 28                                                           \n",
      "Corpus has been loaded: 28 sentences, 694 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "86: _dataset/rucoref/rucoref_texts/News/2009-annan2_ru.txt\n",
      "Load corpus\n",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 624 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 121770.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 27 sentences, 624 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 130769.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 624 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 624 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "87: _dataset/rucoref/rucoref_texts/News/2009-annan3_ru.txt\n",
      "Load corpus\n",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 973 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 36/36 [00:00<00:00, 63230.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been processed: 1 documents, 13 paragraphs, 36 sentences, 973 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 36/36 [00:00<00:00, 145047.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 973 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 973 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 3401: Бреттон-Вудские != Бреттон\n",
      "token 3401: Бреттон-Вудские != Бреттон\n",
      "token 3408 (-) is not found\n",
      "token 3408 (-) is not found\n",
      "token 3409 (Вудские) is not found\n",
      "token 3409 (Вудские) is not found\n",
      "\n",
      "88: _dataset/rucoref/rucoref_texts/News/2009-aslund24_ru.txt\n",
      "Load corpus\n",
      "[=] 47                                                           \n",
      "Corpus has been loaded: 47 sentences, 1030 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 47/47 [00:00<00:00, 406458.33it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 47                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 47 sentences, 1030 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 47                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 47/47 [00:00<00:00, 114545.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 47                                                           \n",
      "Corpus has been loaded: 47 sentences, 1030 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 47                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 47                                                           \n",
      "Corpus has been loaded: 47 sentences, 1030 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 29: премьер-министр != премьер\n",
      "token 29: премьер-министр != премьер\n",
      "token 36 (-) is not found\n",
      "token 36 (-) is not found\n",
      "token 37 (министр) is not found\n",
      "token 37 (министр) is not found\n",
      "token 917:  != ВТО\n",
      "token 917:  != ВТО\n",
      "token 3083:  != 2020\n",
      "token 3083:  != 2020\n",
      "token 3087 (”) is not found\n",
      "token 3087 (”) is not found\n",
      "token 3501:  != инерции\n",
      "token 3501:  != инерции\n",
      "token 3508 (”) is not found\n",
      "token 3508 (”) is not found\n",
      "\n",
      "89: _dataset/rucoref/rucoref_texts/News/2009-asteiner3_ru.txt\n",
      "Load corpus\n",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 805 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 222051.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 27 sentences, 805 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 241463.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 805 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 805 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1625: Мьюнг-Бака != Мьюнг\n",
      "token 1625: Мьюнг-Бака != Мьюнг\n",
      "token 1630 (-) is not found\n",
      "token 1630 (-) is not found\n",
      "token 1631 (Бака) is not found\n",
      "token 1631 (Бака) is not found\n",
      "\n",
      "90: _dataset/rucoref/rucoref_texts/News/2009-asteiner5_ru.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 641 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 54120.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 22 sentences, 641 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 75203.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 641 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 641 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "91: _dataset/rucoref/rucoref_texts/News/2009-avineri35_ru.txt\n",
      "Load corpus\n",
      "[=] 35                                                           \n",
      "Corpus has been loaded: 35 sentences, 797 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 35/35 [00:00<00:00, 298375.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 35 sentences, 797 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 35/35 [00:00<00:00, 128210.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been loaded: 35 sentences, 797 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been loaded: 35 sentences, 797 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 3308: премьер-министр != премьер\n",
      "token 3308: премьер-министр != премьер\n",
      "token 3315 (-) is not found\n",
      "token 3315 (-) is not found\n",
      "token 3316 (министр) is not found\n",
      "token 3316 (министр) is not found\n",
      "\n",
      "92: _dataset/rucoref/rucoref_texts/News/2009-bakker3_ru.txt\n",
      "Load corpus\n",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 757 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 39/39 [00:00<00:00, 256794.12it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been processed: 1 documents, 13 paragraphs, 39 sentences, 757 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 39/39 [00:00<00:00, 313969.01it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 757 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 757 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "93: _dataset/rucoref/rucoref_texts/News/2009-bakker4_ru.txt\n",
      "Load corpus\n",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 816 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 39/39 [00:00<00:00, 342213.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been processed: 1 documents, 13 paragraphs, 39 sentences, 816 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 39/39 [00:00<00:00, 345100.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 816 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 816 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 86: G-20 != G\n",
      "token 86: G-20 != G\n",
      "token 87 (-) is not found\n",
      "token 87 (-) is not found\n",
      "token 88 (20) is not found\n",
      "token 88 (20) is not found\n",
      "token 1119: G-20 != G\n",
      "token 1119: G-20 != G\n",
      "token 1120 (-) is not found\n",
      "token 1120 (-) is not found\n",
      "token 1121 (20) is not found\n",
      "token 1121 (20) is not found\n",
      "token 1687: G-20 != G\n",
      "token 1687: G-20 != G\n",
      "token 1688 (-) is not found\n",
      "token 1688 (-) is not found\n",
      "token 1689 (20) is not found\n",
      "token 1689 (20) is not found\n",
      "token 1687: G-20 != G\n",
      "token 1687: G-20 != G\n",
      "token 1688 (-) is not found\n",
      "token 1688 (-) is not found\n",
      "token 1689 (20) is not found\n",
      "token 1689 (20) is not found\n",
      "token 2429: G-20 != G\n",
      "token 2429: G-20 != G\n",
      "token 2430 (-) is not found\n",
      "token 2430 (-) is not found\n",
      "token 2431 (20) is not found\n",
      "token 2431 (20) is not found\n",
      "token 2521: G-20 != G\n",
      "token 2521: G-20 != G\n",
      "token 2522 (-) is not found\n",
      "token 2522 (-) is not found\n",
      "token 2523 (20) is not found\n",
      "token 2523 (20) is not found\n",
      "token 3066: G-20 != G\n",
      "token 3066: G-20 != G\n",
      "token 3067 (-) is not found\n",
      "token 3067 (-) is not found\n",
      "token 3068 (20) is not found\n",
      "token 3068 (20) is not found\n",
      "token 3066: G-20 != G\n",
      "token 3066: G-20 != G\n",
      "token 3067 (-) is not found\n",
      "token 3067 (-) is not found\n",
      "token 3068 (20) is not found\n",
      "token 3068 (20) is not found\n",
      "token 5023: G-20 != G\n",
      "token 5023: G-20 != G\n",
      "token 5024 (-) is not found\n",
      "token 5024 (-) is not found\n",
      "token 5025 (20) is not found\n",
      "token 5025 (20) is not found\n",
      "\n",
      "94: _dataset/rucoref/rucoref_texts/News/2009-baradei1_ru.txt\n",
      "Load corpus\n",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 943 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 39/39 [00:00<00:00, 180549.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been processed: 1 documents, 15 paragraphs, 39 sentences, 943 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 39/39 [00:00<00:00, 150347.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 943 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 39                                                           \n",
      "Corpus has been loaded: 39 sentences, 943 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 4008: низкообогащенный != низко\n",
      "token 4008: низкообогащенный != низко\n",
      "token 4013 (-) is not found\n",
      "token 4013 (-) is not found\n",
      "token 4014 (обогащенный) is not found\n",
      "token 4014 (обогащенный) is not found\n",
      "\n",
      "95: _dataset/rucoref/rucoref_texts/News/2009-barbarosie1_ru.txt\n",
      "Load corpus\n",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 767 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 36/36 [00:00<00:00, 179542.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 36 sentences, 767 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 36/36 [00:00<00:00, 318554.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 767 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 767 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "96: _dataset/rucoref/rucoref_texts/News/2009-barnett1_ru.txt\n",
      "Load corpus\n",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 1050 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 37/37 [00:00<00:00, 145172.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 37 sentences, 1050 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 37/37 [00:00<00:00, 136370.17it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 1050 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 1050 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "97: _dataset/rucoref/rucoref_texts/News/2009-barroso1_ru.txt\n",
      "Load corpus\n",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 950 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 149639.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 34 sentences, 950 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 111672.93it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 950 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 950 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "98: _dataset/rucoref/rucoref_texts/News/2009-barroso3_ru.txt\n",
      "Load corpus\n",
      "[=] 59                                                           \n",
      "Corpus has been loaded: 59 sentences, 965 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 59/59 [00:00<00:00, 459970.14it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been processed: 1 documents, 15 paragraphs, 59 sentences, 965 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 59/59 [00:00<00:00, 160586.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been loaded: 59 sentences, 965 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been loaded: 59 sentences, 965 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "99: _dataset/rucoref/rucoref_texts/News/2009-beasley1_ru.txt\n",
      "Load corpus\n",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 845 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 301493.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 34 sentences, 845 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 140915.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 845 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 845 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 405: 80-х != 80\n",
      "token 405: 80-х != 80\n",
      "token 407 (-) is not found\n",
      "token 407 (-) is not found\n",
      "token 408 (х) is not found\n",
      "token 408 (х) is not found\n",
      "token 410: гг. != гг\n",
      "token 410: гг. != гг\n",
      "token 1405:  != 200�000\n",
      "token 1405:  != 200�000\n",
      "token 3598: респираторно-синцитиальный != респираторно\n",
      "token 3598: респираторно-синцитиальный != респираторно\n",
      "token 3610 (-) is not found\n",
      "token 3610 (-) is not found\n",
      "token 3611 (синцитиальный) is not found\n",
      "token 3611 (синцитиальный) is not found\n",
      "\n",
      "100: _dataset/rucoref/rucoref_texts/News/2009-bebchuk1_ru.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 732 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 77148.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 30 sentences, 732 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 195386.83it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 732 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 732 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "111: _dataset/rucoref/rucoref_texts/OpenCorpora/347-done.txt\n",
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 375 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 35010.88it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 149796.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 15 sentences, 375 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 375 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 375 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "112: _dataset/rucoref/rucoref_texts/OpenCorpora/388-done.txt\n",
      "Load corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 526 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 61141.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 20 sentences, 526 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 182758.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 526 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 526 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1063: М. != М.П\n",
      "token 1063: М. != М.П\n",
      "token 1066 (.) is not found\n",
      "token 1066 (.) is not found\n",
      "\n",
      "113: _dataset/rucoref/rucoref_texts/Otzyvy/www.turpravda.ru-gr-halkidiki-Potidea_Palace-h13681-r59401.txt\n",
      "Load corpus\n",
      "[=] 40                                                           \n",
      "Corpus has been loaded: 40 sentences, 528 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 40/40 [00:00<00:00, 43262.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 40                                                           \n",
      "Corpus has been processed: 1 documents, 1 paragraphs, 40 sentences, 528 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 40                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 40/40 [00:00<00:00, 109726.72it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 40                                                           \n",
      "Corpus has been loaded: 40 sentences, 528 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 40                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 40                                                           \n",
      "Corpus has been loaded: 40 sentences, 528 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "114: _dataset/rucoref/rucoref_texts/Otzyvy/www.turpravda.ru-gr-halkidiki-Potidea_Palace-h13681-r67576.txt\n",
      "Load corpus\n",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 428 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 81118.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been processed: 1 documents, 1 paragraphs, 17 sentences, 428 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 148858.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 428 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 428 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 298 (моему) is not found\n",
      "token 298 (моему) is not found\n",
      "\n",
      "115: _dataset/rucoref/rucoref_texts/Otzyvy/www.turpravda.ru-gr-halkidiki-Potidea_Palace-h13681-r68708.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 445 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 52015.04it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 104147.50it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 22 sentences, 445 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 445 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 445 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 73: нем. != нем\n",
      "token 73: нем. != нем\n",
      "token 288: 4+ != 4\n",
      "token 288: 4+ != 4\n",
      "token 289 (+) is not found\n",
      "token 289 (+) is not found\n",
      "token 1300: Гуру != гуру\n",
      "token 1300: Гуру != гуру\n",
      "\n",
      "116: _dataset/rucoref/rucoref_texts/Otzyvy/www.turpravda.ru-gr-halkidiki-Potidea_Palace-h13681-r69802.txt\n",
      "Load corpus\n",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 330 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 129869.50it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 185345.68it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been processed: 1 documents, 1 paragraphs, 27 sentences, 330 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 330 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 330 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "117: _dataset/rucoref/rucoref_texts/Otzyvy/www.turpravda.ru-gr-halkidiki-Potidea_Palace-h13681-r72202.txt\n",
      "Load corpus\n",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 1016 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 186759.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 24 sentences, 1016 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 86853.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 1016 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 1016 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "118: _dataset/rucoref/rucoref_texts/PhotoDescr/PhotoDescr1.txt\n",
      "Load corpus\n",
      "[=] 6                                                            \n",
      "Corpus has been loaded: 6 sentences, 107 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 6/6 [00:00<00:00, 57719.78it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 6/6 [00:00<00:00, 66225.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been processed: 1 documents, 1 paragraphs, 6 sentences, 107 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been loaded: 6 sentences, 107 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been loaded: 6 sentences, 107 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "119: _dataset/rucoref/rucoref_texts/PhotoDescr/PhotoDescr11.txt\n",
      "Load corpus\n",
      "[=] 9                                                            \n",
      "Corpus has been loaded: 9 sentences, 187 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 9/9 [00:00<00:00, 28361.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 9                                                           \n",
      "Corpus has been processed: 1 documents, 2 paragraphs, 9 sentences, 187 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 9                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 9/9 [00:00<00:00, 86381.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 9                                                           \n",
      "Corpus has been loaded: 9 sentences, 187 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 9                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 9                                                           \n",
      "Corpus has been loaded: 9 sentences, 187 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 28: какого-то != какого\n",
      "token 28: какого-то != какого\n",
      "token 34 (-) is not found\n",
      "token 34 (-) is not found\n",
      "token 35 (то) is not found\n",
      "token 35 (то) is not found\n",
      "\n",
      "120: _dataset/rucoref/rucoref_texts/PhotoDescr/PhotoDescr15.txt\n",
      "Load corpus\n",
      "[=] 6                                                            \n",
      "Corpus has been loaded: 6 sentences, 83 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 6/6 [00:00<00:00, 34952.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been processed: 1 documents, 1 paragraphs, 6 sentences, 83 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 6/6 [00:00<00:00, 25140.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been loaded: 6 sentences, 83 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 6                                                           \n",
      "Corpus has been loaded: 6 sentences, 83 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "131: _dataset/rucoref/rucoref_texts/Science/nauka i zhizn_mars.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "[=] 174                                                           \n",
      "Corpus has been processed: 1 documents, 55 paragraphs, 174 sentences, 3704 tokens\n",
      "Save corpus\n",
      "[=] 174                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 174                                                           \n",
      "Corpus has been loaded: 174 sentences, 3704 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 174/174 [00:01<00:00, 158.88it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 174/174 [00:01<00:00, 158.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been loaded: 174 sentences, 3704 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been loaded: 174 sentences, 3704 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "132: _dataset/rucoref/rucoref_texts/Science/nauka i zhizn_pererabotka.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 95                                                           \n",
      "Corpus has been loaded: 95 sentences, 1812 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/95 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 95                                                           \n",
      "Corpus has been processed: 1 documents, 46 paragraphs, 95 sentences, 1812 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 95                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 95/95 [00:00<00:00, 184.50it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 95/95 [00:00<00:00, 184.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 95                                                           \n",
      "Corpus has been loaded: 95 sentences, 1812 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 95                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 95                                                           \n",
      "Corpus has been loaded: 95 sentences, 1812 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "133: _dataset/rucoref/rucoref_texts/Science/philology.ru-linguistics1-alpatov-12-out2.txt\n",
      "Load corpus\n",
      "[=] 46                                                           \n",
      "Corpus has been loaded: 46 sentences, 1108 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 46/46 [00:00<00:00, 94346.20it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 46                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 46 sentences, 1108 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 46                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 46/46 [00:00<00:00, 152279.39it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 46                                                           \n",
      "Corpus has been loaded: 46 sentences, 1108 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 46                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 46                                                           \n",
      "Corpus has been loaded: 46 sentences, 1108 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1453: Ф. != Ф.Л\n",
      "token 1453: Ф. != Ф.Л\n",
      "token 1456 (.) is not found\n",
      "token 1456 (.) is not found\n",
      "token 2734: кто-то != кто\n",
      "token 2734: кто-то != кто\n",
      "token 2737 (-) is not found\n",
      "token 2737 (-) is not found\n",
      "token 2738 (то) is not found\n",
      "token 2738 (то) is not found\n",
      "token 4711: Н. != Н.Я\n",
      "token 4711: Н. != Н.Я\n",
      "token 4714 (.) is not found\n",
      "token 4714 (.) is not found\n",
      "token 4860: Н. != Н\n",
      "token 4860: Н. != Н\n",
      "token 4861 (.) is not found\n",
      "token 4861 (.) is not found\n",
      "token 4863: Я. != Я\n",
      "token 4863: Я. != Я\n",
      "token 4864 (.) is not found\n",
      "token 4864 (.) is not found\n",
      "token 5106: Н. != Н.Я\n",
      "token 5106: Н. != Н.Я\n",
      "token 5109 (.) is not found\n",
      "token 5109 (.) is not found\n",
      "token 5703: Н. != Н.Я\n",
      "token 5703: Н. != Н.Я\n",
      "token 5706 (.) is not found\n",
      "token 5706 (.) is not found\n",
      "token 5967: Н. != Н.Я\n",
      "token 5967: Н. != Н.Я\n",
      "token 5970 (.) is not found\n",
      "token 5970 (.) is not found\n",
      "token 6441: Н. != Н.Я\n",
      "token 6441: Н. != Н.Я\n",
      "token 6444 (.) is not found\n",
      "token 6444 (.) is not found\n",
      "\n",
      "134: _dataset/rucoref/rucoref_texts/Science/philology.ru-linguistics1-barannikov-46-out2.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been loaded: 128 sentences, 2597 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been processed: 1 documents, 37 paragraphs, 128 sentences, 2597 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 137.43it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 128/128 [00:00<00:00, 138.48it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been loaded: 128 sentences, 2597 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been loaded: 128 sentences, 2597 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 820: акад. != акад\n",
      "token 820: акад. != акад\n",
      "token 824 (.) is not found\n",
      "token 824 (.) is not found\n",
      "token 826: П. != П\n",
      "token 826: П. != П\n",
      "token 827 (.) is not found\n",
      "token 827 (.) is not found\n",
      "token 829: С. != С\n",
      "token 829: С. != С\n",
      "token 830 (.) is not found\n",
      "token 830 (.) is not found\n",
      "token 3081: Г. != Г.С\n",
      "token 3081: Г. != Г.С\n",
      "token 3084 (.) is not found\n",
      "token 3084 (.) is not found\n",
      "token 3096: Г. != Г.С\n",
      "token 3096: Г. != Г.С\n",
      "token 3099 (.) is not found\n",
      "token 3099 (.) is not found\n",
      "token 4013: Г. != Г.С\n",
      "token 4013: Г. != Г.С\n",
      "token 4016 (.) is not found\n",
      "token 4016 (.) is not found\n",
      "token 4467: Г. != Г.С\n",
      "token 4467: Г. != Г.С\n",
      "token 4470 (.) is not found\n",
      "token 4470 (.) is not found\n",
      "token 4736: Г. != Г.С\n",
      "token 4736: Г. != Г.С\n",
      "token 4739 (.) is not found\n",
      "token 4739 (.) is not found\n",
      "token 5587: Г. != Г.С\n",
      "token 5587: Г. != Г.С\n",
      "token 5590 (.) is not found\n",
      "token 5590 (.) is not found\n",
      "token 5635: в. != в\n",
      "token 5635: в. != в\n",
      "token 5636 (.) is not found\n",
      "token 5636 (.) is not found\n",
      "token 6543: Н. != Н.М\n",
      "token 6543: Н. != Н.М\n",
      "token 6546 (.) is not found\n",
      "token 6546 (.) is not found\n",
      "token 7066: S. != S\n",
      "token 7066: S. != S\n",
      "token 7067 (.) is not found\n",
      "token 7067 (.) is not found\n",
      "token 10094: б. != б\n",
      "token 10094: б. != б\n",
      "token 10095 (.) is not found\n",
      "token 10095 (.) is not found\n",
      "token 10908: проф. != проф\n",
      "token 10908: проф. != проф\n",
      "token 10912 (.) is not found\n",
      "token 10912 (.) is not found\n",
      "token 10914: В. != В.П\n",
      "token 10914: В. != В.П\n",
      "token 10917 (.) is not found\n",
      "token 10917 (.) is not found\n",
      "token 10984: проф. != проф\n",
      "token 10984: проф. != проф\n",
      "token 10988 (.) is not found\n",
      "token 10988 (.) is not found\n",
      "token 10990: И. != И.П\n",
      "token 10990: И. != И.П\n",
      "token 10993 (.) is not found\n",
      "token 10993 (.) is not found\n",
      "token 11051: И. != И.П\n",
      "token 11051: И. != И.П\n",
      "token 11054 (.) is not found\n",
      "token 11054 (.) is not found\n",
      "token 11363: И. != И.П\n",
      "token 11363: И. != И.П\n",
      "token 11366 (.) is not found\n",
      "token 11366 (.) is not found\n",
      "token 11531: И. != И.П\n",
      "token 11531: И. != И.П\n",
      "token 11534 (.) is not found\n",
      "token 11534 (.) is not found\n",
      "token 12000: И. != И.П\n",
      "token 12000: И. != И.П\n",
      "token 12003 (.) is not found\n",
      "token 12003 (.) is not found\n",
      "token 12092: проф. != проф\n",
      "token 12092: проф. != проф\n",
      "token 12096 (.) is not found\n",
      "token 12096 (.) is not found\n",
      "token 12098: И. != И.П\n",
      "token 12098: И. != И.П\n",
      "token 12101 (.) is not found\n",
      "token 12101 (.) is not found\n",
      "token 12305: акад. != акад\n",
      "token 12305: акад. != акад\n",
      "token 12309 (.) is not found\n",
      "token 12309 (.) is not found\n",
      "token 12311: С. != С.Ф\n",
      "token 12311: С. != С.Ф\n",
      "token 12314 (.) is not found\n",
      "token 12314 (.) is not found\n",
      "token 12328: Акад. != Акад\n",
      "token 12328: Акад. != Акад\n",
      "token 12332 (.) is not found\n",
      "token 12332 (.) is not found\n",
      "token 12334: Ф. != Ф.И\n",
      "token 12334: Ф. != Ф.И\n",
      "token 12337 (.) is not found\n",
      "token 12337 (.) is not found\n",
      "token 12715: проф. != проф\n",
      "token 12715: проф. != проф\n",
      "token 12719 (.) is not found\n",
      "token 12719 (.) is not found\n",
      "token 12721: И. != И.П\n",
      "token 12721: И. != И.П\n",
      "token 12724 (.) is not found\n",
      "token 12724 (.) is not found\n",
      "token 12999: С. != С.Ф\n",
      "token 12999: С. != С.Ф\n",
      "token 13002 (.) is not found\n",
      "token 13002 (.) is not found\n",
      "token 13017: акад. != акад\n",
      "token 13017: акад. != акад\n",
      "token 13021 (.) is not found\n",
      "token 13021 (.) is not found\n",
      "token 13023: Ф. != Ф.И\n",
      "token 13023: Ф. != Ф.И\n",
      "token 13026 (.) is not found\n",
      "token 13026 (.) is not found\n",
      "token 13054: Е. != Е\n",
      "token 13054: Е. != Е\n",
      "token 13055 (.) is not found\n",
      "token 13055 (.) is not found\n",
      "token 12999: С. != С.Ф\n",
      "token 12999: С. != С.Ф\n",
      "token 13002 (.) is not found\n",
      "token 13002 (.) is not found\n",
      "token 13017: акад. != акад\n",
      "token 13017: акад. != акад\n",
      "token 13021 (.) is not found\n",
      "token 13021 (.) is not found\n",
      "token 13023: Ф. != Ф.И\n",
      "token 13023: Ф. != Ф.И\n",
      "token 13026 (.) is not found\n",
      "token 13026 (.) is not found\n",
      "token 12999: С. != С.Ф\n",
      "token 12999: С. != С.Ф\n",
      "token 13002 (.) is not found\n",
      "token 13002 (.) is not found\n",
      "token 13017: акад. != акад\n",
      "token 13017: акад. != акад\n",
      "token 13021 (.) is not found\n",
      "token 13021 (.) is not found\n",
      "token 13023: Ф. != Ф.И\n",
      "token 13023: Ф. != Ф.И\n",
      "token 13026 (.) is not found\n",
      "token 13026 (.) is not found\n",
      "token 13054: Е. != Е\n",
      "token 13054: Е. != Е\n",
      "token 13055 (.) is not found\n",
      "token 13055 (.) is not found\n",
      "token 13173: акад. != акад\n",
      "token 13173: акад. != акад\n",
      "token 13177 (.) is not found\n",
      "token 13177 (.) is not found\n",
      "token 13243: акад. != акад\n",
      "token 13243: акад. != акад\n",
      "token 13247 (.) is not found\n",
      "token 13247 (.) is not found\n",
      "token 13602: Р. != Р\n",
      "token 13602: Р. != Р\n",
      "token 13603 (.) is not found\n",
      "token 13603 (.) is not found\n",
      "token 14909: Л. != Л\n",
      "token 14909: Л. != Л\n",
      "token 14910 (.) is not found\n",
      "token 14910 (.) is not found\n",
      "token 14922: М. != М\n",
      "token 14922: М. != М\n",
      "token 14923 (.) is not found\n",
      "token 14923 (.) is not found\n",
      "token 15076: Л. != Л\n",
      "token 15076: Л. != Л\n",
      "token 15077 (.) is not found\n",
      "token 15077 (.) is not found\n",
      "token 15352: М. != М\n",
      "token 15352: М. != М\n",
      "token 15353 (.) is not found\n",
      "token 15353 (.) is not found\n",
      "token 15561: Р. != Р\n",
      "token 15561: Р. != Р\n",
      "token 15562 (.) is not found\n",
      "token 15562 (.) is not found\n",
      "\n",
      "202: _dataset/rucoref/rucoref_texts/OFC/2.txt\n",
      "Load corpus\n",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 1018 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 42/42 [00:00<00:00, 306900.29it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been processed: 1 documents, 42 paragraphs, 42 sentences, 1018 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 42/42 [00:00<00:00, 97758.47it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 1018 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 1018 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 233: ток-шоу != ток\n",
      "token 233: ток-шоу != ток\n",
      "token 236 (-) is not found\n",
      "token 236 (-) is not found\n",
      "token 237 (шоу) is not found\n",
      "token 237 (шоу) is not found\n",
      "token 3110: О. != О.С.П.\n",
      "token 3110: О. != О.С.П.\n",
      "token 233: ток-шоу != ток\n",
      "token 233: ток-шоу != ток\n",
      "token 236 (-) is not found\n",
      "token 236 (-) is not found\n",
      "token 237 (шоу) is not found\n",
      "token 237 (шоу) is not found\n",
      "\n",
      "203: _dataset/rucoref/rucoref_texts/OFC/3.txt\n",
      "Load corpus\n",
      "[=] 12                                                           \n",
      "Corpus has been loaded: 12 sentences, 318 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 12/12 [00:00<00:00, 41187.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 12                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 12 sentences, 318 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 12                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 12/12 [00:00<00:00, 68853.14it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 12                                                           \n",
      "Corpus has been loaded: 12 sentences, 318 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 12                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 12                                                           \n",
      "Corpus has been loaded: 12 sentences, 318 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 434: 100-метровый != 100\n",
      "token 434: 100-метровый != 100\n",
      "token 437 (-) is not found\n",
      "token 437 (-) is not found\n",
      "token 438 (метровый) is not found\n",
      "token 438 (метровый) is not found\n",
      "token 434: 100-метровый != 100\n",
      "token 434: 100-метровый != 100\n",
      "token 437 (-) is not found\n",
      "token 437 (-) is not found\n",
      "token 438 (метровый) is not found\n",
      "token 438 (метровый) is not found\n",
      "\n",
      "204: _dataset/rucoref/rucoref_texts/OFC/4.txt\n",
      "Load corpus\n",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1304 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 60/60 [00:00<00:00, 272062.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been processed: 1 documents, 55 paragraphs, 60 sentences, 1304 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 60/60 [00:00<00:00, 230667.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1304 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1304 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1501 (–) is not found\n",
      "token 1501 (–) is not found\n",
      "token 1576: Уивера-старшего != Уивера\n",
      "token 1576: Уивера-старшего != Уивера\n",
      "token 1582 (-) is not found\n",
      "token 1582 (-) is not found\n",
      "token 1583 (старшего) is not found\n",
      "token 1583 (старшего) is not found\n",
      "token 2458: Уивер-младший != Уивер\n",
      "token 2458: Уивер-младший != Уивер\n",
      "token 2463 (-) is not found\n",
      "token 2463 (-) is not found\n",
      "token 2464 (младший) is not found\n",
      "token 2464 (младший) is not found\n",
      "\n",
      "205: _dataset/rucoref/rucoref_texts/OFC/5.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been loaded: 128 sentences, 1348 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been processed: 1 documents, 128 paragraphs, 128 sentences, 1348 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 128/128 [00:00<00:00, 221.55it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 128/128 [00:00<00:00, 219.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been loaded: 128 sentences, 1348 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 128                                                           \n",
      "Corpus has been loaded: 128 sentences, 1348 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 1152: хеппи-энд != хеппи\n",
      "token 1152: хеппи-энд != хеппи\n",
      "token 1157 (-) is not found\n",
      "token 1157 (-) is not found\n",
      "token 1158 (энд) is not found\n",
      "token 1158 (энд) is not found\n",
      "\n",
      "207: _dataset/rucoref/rucoref_texts/OFC/7.txt\n",
      "Load corpus\n",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 1139 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 118434.20it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been processed: 1 documents, 41 paragraphs, 41 sentences, 1139 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 335872.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 1139 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 1139 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "209: _dataset/rucoref/rucoref_texts/OFC/9.txt\n",
      "Load corpus\n",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 583 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 25/25 [00:00<00:00, 97541.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been processed: 1 documents, 25 paragraphs, 25 sentences, 583 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 25/25 [00:00<00:00, 62788.98it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 583 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 583 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 3640: ARPA-E != ARPA\n",
      "token 3640: ARPA-E != ARPA\n",
      "token 3644 (-) is not found\n",
      "token 3644 (-) is not found\n",
      "token 3645 (E) is not found\n",
      "token 3645 (E) is not found\n",
      "\n",
      "210: _dataset/rucoref/rucoref_texts/OFC/10.txt\n",
      "Load corpus\n",
      "[=] 32                                                           \n",
      "Corpus has been loaded: 32 sentences, 730 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 32/32 [00:00<00:00, 94987.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 32                                                           \n",
      "Corpus has been processed: 1 documents, 32 paragraphs, 32 sentences, 730 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 32                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 32/32 [00:00<00:00, 123817.09it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 32                                                           \n",
      "Corpus has been loaded: 32 sentences, 730 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 32                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 32                                                           \n",
      "Corpus has been loaded: 32 sentences, 730 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "211: _dataset/rucoref/rucoref_texts/OFC/11.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1898 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been processed: 1 documents, 97 paragraphs, 103 sentences, 1898 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 205.55it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 103/103 [00:00<00:00, 204.15it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1898 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1898 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 3357: какие-то != какие\n",
      "token 3357: какие-то != какие\n",
      "token 3362 (-) is not found\n",
      "token 3362 (-) is not found\n",
      "token 3363 (то) is not found\n",
      "token 3363 (то) is not found\n",
      "token 4485: ВАЗ-2108 != ВАЗ\n",
      "token 4485: ВАЗ-2108 != ВАЗ\n",
      "token 4488 (-) is not found\n",
      "token 4488 (-) is not found\n",
      "token 4489 (2108) is not found\n",
      "token 4489 (2108) is not found\n",
      "\n",
      "212: _dataset/rucoref/rucoref_texts/OFC/12.txt\n",
      "Load corpus\n",
      "[=] 55                                                           \n",
      "Corpus has been loaded: 55 sentences, 1215 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 55/55 [00:00<00:00, 201825.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 55                                                           \n",
      "Corpus has been processed: 1 documents, 54 paragraphs, 55 sentences, 1215 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 55                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 55/55 [00:00<00:00, 429584.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 55                                                           \n",
      "Corpus has been loaded: 55 sentences, 1215 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 55                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 55                                                           \n",
      "Corpus has been loaded: 55 sentences, 1215 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 2162 (—) is not found\n",
      "token 2162 (—) is not found\n",
      "token 3679: F-117А != F\n",
      "token 3679: F-117А != F\n",
      "token 3680 (-) is not found\n",
      "token 3680 (-) is not found\n",
      "token 3681 (117А) is not found\n",
      "token 3681 (117А) is not found\n",
      "token 3807: F-117 != F\n",
      "token 3807: F-117 != F\n",
      "token 3808 (-) is not found\n",
      "token 3808 (-) is not found\n",
      "token 3809 (117) is not found\n",
      "token 3809 (117) is not found\n",
      "token 4225: F-117 != F\n",
      "token 4225: F-117 != F\n",
      "token 4226 (-) is not found\n",
      "token 4226 (-) is not found\n",
      "token 4227 (117) is not found\n",
      "token 4227 (117) is not found\n",
      "\n",
      "215: _dataset/rucoref/rucoref_texts/OFC/15.txt\n",
      "Load corpus\n",
      "[=] 62                                                           \n",
      "Corpus has been loaded: 62 sentences, 1126 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 62/62 [00:00<00:00, 216525.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 62                                                           \n",
      "Corpus has been processed: 1 documents, 61 paragraphs, 62 sentences, 1126 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 62                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 62/62 [00:00<00:00, 162427.76it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 62                                                           \n",
      "Corpus has been loaded: 62 sentences, 1126 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 62                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 62                                                           \n",
      "Corpus has been loaded: 62 sentences, 1126 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 125: 27-летняя != 27\n",
      "token 125: 27-летняя != 27\n",
      "token 127 (-) is not found\n",
      "token 127 (-) is not found\n",
      "token 128 (летняя) is not found\n",
      "token 128 (летняя) is not found\n",
      "token 680: Горно-Алтайска != Горно\n",
      "token 680: Горно-Алтайска != Горно\n",
      "token 685 (-) is not found\n",
      "token 685 (-) is not found\n",
      "token 686 (Алтайска) is not found\n",
      "token 686 (Алтайска) is not found\n",
      "token 680: Горно-Алтайска != Горно\n",
      "token 680: Горно-Алтайска != Горно\n",
      "token 685 (-) is not found\n",
      "token 685 (-) is not found\n",
      "token 686 (Алтайска) is not found\n",
      "token 686 (Алтайска) is not found\n",
      "token 2764: госпожой != г\n",
      "token 2764: госпожой != г\n",
      "token 2765 (-) is not found\n",
      "token 2765 (-) is not found\n",
      "token 2766 (жой) is not found\n",
      "token 2766 (жой) is not found\n",
      "token 3013: госпожи != г\n",
      "token 3013: госпожи != г\n",
      "token 3014 (-) is not found\n",
      "token 3014 (-) is not found\n",
      "token 3015 (жи) is not found\n",
      "token 3015 (жи) is not found\n",
      "token 3841: Горно-Алтайска != Горно\n",
      "token 3841: Горно-Алтайска != Горно\n",
      "token 3846 (-) is not found\n",
      "token 3846 (-) is not found\n",
      "token 3847 (Алтайска) is not found\n",
      "token 3847 (Алтайска) is not found\n",
      "token 4350: 19-летняя != 19\n",
      "token 4350: 19-летняя != 19\n",
      "token 4352 (-) is not found\n",
      "token 4352 (-) is not found\n",
      "token 4353 (летняя) is not found\n",
      "token 4353 (летняя) is not found\n",
      "\n",
      "219: _dataset/rucoref/rucoref_texts/OFC/19.txt\n",
      "Load corpus\n",
      "[=] 59                                                           \n",
      "Corpus has been loaded: 59 sentences, 1241 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 59/59 [00:00<00:00, 396576.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been processed: 1 documents, 58 paragraphs, 59 sentences, 1241 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 59/59 [00:00<00:00, 239790.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been loaded: 59 sentences, 1241 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 59                                                           \n",
      "Corpus has been loaded: 59 sentences, 1241 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "251: _dataset/rucoref/rucoref_texts/OFC/51.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 100                                                           \n",
      "Corpus has been loaded: 100 sentences, 1948 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/100 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 100                                                           \n",
      "Corpus has been processed: 1 documents, 99 paragraphs, 100 sentences, 1948 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 100                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:00<00:00, 210.20it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 100/100 [00:00<00:00, 210.59it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 100                                                           \n",
      "Corpus has been loaded: 100 sentences, 1948 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 100                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 100                                                           \n",
      "Corpus has been loaded: 100 sentences, 1948 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 642: Вояджером-2 != Вояджером\n",
      "token 642: Вояджером-2 != Вояджером\n",
      "token 651 (-) is not found\n",
      "token 651 (-) is not found\n",
      "token 652 (2) is not found\n",
      "token 652 (2) is not found\n",
      "token 863:  != 1986U2R\n",
      "token 863:  != 1986U2R\n",
      "token 870 (/) is not found\n",
      "token 870 (/) is not found\n",
      "token 871 (ζ) is not found\n",
      "token 871 (ζ) is not found\n",
      "token 883:  != α\n",
      "token 883:  != α\n",
      "token 886:  != β\n",
      "token 886:  != β\n",
      "token 889:  != η\n",
      "token 889:  != η\n",
      "token 892:  != γ\n",
      "token 892:  != γ\n",
      "token 895:  != δ\n",
      "token 895:  != δ\n",
      "token 898:  != λ\n",
      "token 898:  != λ\n",
      "token 901:  != ε\n",
      "token 901:  != ε\n",
      "token 904:  != ν\n",
      "token 904:  != ν\n",
      "token 908:  != μ\n",
      "token 908:  != μ\n",
      "token 943:  != 1986U2R\n",
      "token 943:  != 1986U2R\n",
      "token 950 (/) is not found\n",
      "token 950 (/) is not found\n",
      "token 951 (ζ) is not found\n",
      "token 951 (ζ) is not found\n",
      "token 988:  != μ\n",
      "token 988:  != μ\n",
      "token 1537:  != 1986U2R\n",
      "token 1537:  != 1986U2R\n",
      "token 1544 (/) is not found\n",
      "token 1544 (/) is not found\n",
      "token 1545 (ζ) is not found\n",
      "token 1545 (ζ) is not found\n",
      "token 1548:  != μ\n",
      "token 1548:  != μ\n",
      "token 1552:  != ν\n",
      "token 1552:  != ν\n",
      "token 1609:  != λ\n",
      "token 1609:  != λ\n",
      "token 2397: Вояджер-2 != Вояджер\n",
      "token 2397: Вояджер-2 != Вояджер\n",
      "token 2404 (-) is not found\n",
      "token 2404 (-) is not found\n",
      "token 2405 (2) is not found\n",
      "token 2405 (2) is not found\n",
      "token 2500:  != ε\n",
      "token 2500:  != ε\n",
      "token 3386: L. != L\n",
      "token 3386: L. != L\n",
      "token 3387 (.) is not found\n",
      "token 3387 (.) is not found\n",
      "token 3430: W. != W\n",
      "token 3430: W. != W\n",
      "token 3431 (.) is not found\n",
      "token 3431 (.) is not found\n",
      "token 3474: J. != J\n",
      "token 3474: J. != J\n",
      "token 3475 (.) is not found\n",
      "token 3475 (.) is not found\n",
      "token 3544: P. != P\n",
      "token 3544: P. != P\n",
      "token 3545 (.) is not found\n",
      "token 3545 (.) is not found\n",
      "token 3992: Вояджер-2 != Вояджер\n",
      "token 3992: Вояджер-2 != Вояджер\n",
      "token 3999 (-) is not found\n",
      "token 3999 (-) is not found\n",
      "token 4000 (2) is not found\n",
      "token 4000 (2) is not found\n",
      "token 5289:  != 1986U2R\n",
      "token 5289:  != 1986U2R\n",
      "token 5296 (/) is not found\n",
      "token 5296 (/) is not found\n",
      "token 5297 (ζ) is not found\n",
      "token 5297 (ζ) is not found\n",
      "token 5309:  != α\n",
      "token 5309:  != α\n",
      "token 5312:  != β\n",
      "token 5312:  != β\n",
      "token 5315:  != η\n",
      "token 5315:  != η\n",
      "token 5318:  != γ\n",
      "token 5318:  != γ\n",
      "token 5321:  != δ\n",
      "token 5321:  != δ\n",
      "token 5324:  != λ\n",
      "token 5324:  != λ\n",
      "token 5327:  != ε\n",
      "token 5327:  != ε\n",
      "token 5330:  != ν\n",
      "token 5330:  != ν\n",
      "token 5335:  != μ\n",
      "token 5335:  != μ\n",
      "token 5409:  != α\n",
      "token 5409:  != α\n",
      "token 5412:  != β\n",
      "token 5412:  != β\n",
      "token 5415:  != η\n",
      "token 5415:  != η\n",
      "token 5418:  != γ\n",
      "token 5418:  != γ\n",
      "token 5421:  != δ\n",
      "token 5421:  != δ\n",
      "token 5424:  != ε\n",
      "token 5424:  != ε\n",
      "token 5448:  != 1986U2R\n",
      "token 5448:  != 1986U2R\n",
      "token 5455 (/) is not found\n",
      "token 5455 (/) is not found\n",
      "token 5456 (ζ) is not found\n",
      "token 5456 (ζ) is not found\n",
      "token 5459:  != λ\n",
      "token 5459:  != λ\n",
      "token 5484:  != μ\n",
      "token 5484:  != μ\n",
      "token 5487:  != ν\n",
      "token 5487:  != ν\n",
      "token 5620:  != 1986U2R\n",
      "token 5620:  != 1986U2R\n",
      "token 5627 (/) is not found\n",
      "token 5627 (/) is not found\n",
      "token 5628 (ζ) is not found\n",
      "token 5628 (ζ) is not found\n",
      "token 5631:  != η\n",
      "token 5631:  != η\n",
      "token 5634:  != δ\n",
      "token 5634:  != δ\n",
      "token 5637:  != λ\n",
      "token 5637:  != λ\n",
      "token 5640:  != ν\n",
      "token 5640:  != ν\n",
      "token 5644:  != μ\n",
      "token 5644:  != μ\n",
      "token 6162: Вояджером-2 != Вояджером\n",
      "token 6162: Вояджером-2 != Вояджером\n",
      "token 6171 (-) is not found\n",
      "token 6171 (-) is not found\n",
      "token 6172 (2) is not found\n",
      "token 6172 (2) is not found\n",
      "token 7578:  != ε\n",
      "token 7578:  != ε\n",
      "token 8127:  != ε\n",
      "token 8127:  != ε\n",
      "token 8146:  != ε\n",
      "token 8146:  != ε\n",
      "token 9138: Вояджером-2 != Вояджером\n",
      "token 9138: Вояджером-2 != Вояджером\n",
      "token 9147 (-) is not found\n",
      "token 9147 (-) is not found\n",
      "token 9148 (2) is not found\n",
      "token 9148 (2) is not found\n",
      "token 9167:  != ε\n",
      "token 9167:  != ε\n",
      "token 9377: Вояджера-2 != Вояджера\n",
      "token 9377: Вояджера-2 != Вояджера\n",
      "token 9385 (-) is not found\n",
      "token 9385 (-) is not found\n",
      "token 9386 (2) is not found\n",
      "token 9386 (2) is not found\n",
      "token 9544:  != ε\n",
      "token 9544:  != ε\n",
      "token 9673:  != ε\n",
      "token 9673:  != ε\n",
      "token 9841:  != ε\n",
      "token 9841:  != ε\n",
      "token 10137:  != ε\n",
      "token 10137:  != ε\n",
      "token 10391: Вояджер-2 != Вояджер\n",
      "token 10391: Вояджер-2 != Вояджер\n",
      "token 10398 (-) is not found\n",
      "token 10398 (-) is not found\n",
      "token 10399 (2) is not found\n",
      "token 10399 (2) is not found\n",
      "token 10668:  != ε\n",
      "token 10668:  != ε\n",
      "token 10739:  != ε\n",
      "token 10739:  != ε\n",
      "token 11157:  != ε\n",
      "token 11157:  != ε\n",
      "token 3386: L. != L\n",
      "token 3386: L. != L\n",
      "token 3387 (.) is not found\n",
      "token 3387 (.) is not found\n",
      "token 3430: W. != W\n",
      "token 3430: W. != W\n",
      "token 3431 (.) is not found\n",
      "token 3431 (.) is not found\n",
      "token 3474: J. != J\n",
      "token 3474: J. != J\n",
      "token 3475 (.) is not found\n",
      "token 3475 (.) is not found\n",
      "token 3544: P. != P\n",
      "token 3544: P. != P\n",
      "token 3545 (.) is not found\n",
      "token 3545 (.) is not found\n",
      "\n",
      "252: _dataset/rucoref/rucoref_texts/OFC/52.txt\n",
      "Load corpus\n",
      "[=] 38                                                           \n",
      "Corpus has been loaded: 38 sentences, 952 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 38/38 [00:00<00:00, 101842.53it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been processed: 1 documents, 36 paragraphs, 38 sentences, 952 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 38/38 [00:00<00:00, 233358.06it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been loaded: 38 sentences, 952 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 38                                                           \n",
      "Corpus has been loaded: 38 sentences, 952 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1675: мега-популярная != мега\n",
      "token 1675: мега-популярная != мега\n",
      "token 1679 (-) is not found\n",
      "token 1679 (-) is not found\n",
      "token 1680 (популярная) is not found\n",
      "token 1680 (популярная) is not found\n",
      "\n",
      "253: _dataset/rucoref/rucoref_texts/OFC/53.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 164                                                           \n",
      "Corpus has been loaded: 164 sentences, 3176 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/164 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 164                                                           \n",
      "Corpus has been processed: 1 documents, 161 paragraphs, 164 sentences, 3176 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 164                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 164/164 [00:00<00:00, 200.08it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 164/164 [00:00<00:00, 198.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 164                                                           \n",
      "Corpus has been loaded: 164 sentences, 3176 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 164                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 164                                                           \n",
      "Corpus has been loaded: 164 sentences, 3176 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 3420: агууу-агууу != агууу\n",
      "token 3420: агууу-агууу != агууу\n",
      "token 3425 (-) is not found\n",
      "token 3425 (-) is not found\n",
      "token 3426 (агууу) is not found\n",
      "token 3426 (агууу) is not found\n",
      "token 2349: гаги-гребенушки != гаги\n",
      "token 2349: гаги-гребенушки != гаги\n",
      "token 2354 (гребенушки) is not found\n",
      "token 2354 (гребенушки) is not found\n",
      "token 18502:  != ἔ\n",
      "token 18502:  != ἔ\n",
      "token 18503 (ρ) is not found\n",
      "token 18503 (ρ) is not found\n",
      "token 18504 (ι) is not found\n",
      "token 18504 (ι) is not found\n",
      "token 18505 (ο) is not found\n",
      "token 18505 (ο) is not found\n",
      "token 18506 (ν) is not found\n",
      "token 18506 (ν) is not found\n",
      "\n",
      "254: _dataset/rucoref/rucoref_texts/OFC/54.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been loaded: 69 sentences, 1272 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been processed: 1 documents, 67 paragraphs, 69 sentences, 1272 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:00<00:00, 181.46it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 69/69 [00:00<00:00, 180.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been loaded: 69 sentences, 1272 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been loaded: 69 sentences, 1272 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 897: ток-шоу != ток\n",
      "token 897: ток-шоу != ток\n",
      "token 900 (-) is not found\n",
      "token 900 (-) is not found\n",
      "token 901 (шоу) is not found\n",
      "token 901 (шоу) is not found\n",
      "token 1228: какой-нибудь != какой\n",
      "token 1228: какой-нибудь != какой\n",
      "token 1233 (-) is not found\n",
      "token 1233 (-) is not found\n",
      "token 1234 (нибудь) is not found\n",
      "token 1234 (нибудь) is not found\n",
      "\n",
      "255: _dataset/rucoref/rucoref_texts/OFC/55.txt\n",
      "Load corpus\n",
      "[=] 50                                                           \n",
      "Corpus has been loaded: 50 sentences, 831 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 50/50 [00:00<00:00, 185260.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been processed: 1 documents, 49 paragraphs, 50 sentences, 831 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 50/50 [00:00<00:00, 167237.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been loaded: 50 sentences, 831 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been loaded: 50 sentences, 831 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "257: _dataset/rucoref/rucoref_texts/OFC/57.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 286 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 67728.09it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 179572.65it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 14 paragraphs, 14 sentences, 286 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 286 tokens\n",
      "Save corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 286 tokens\n",
      "Load corpus... done.\n",
      "Preprocess corpus\n",
      "[=] 34                                                           \n",
      "Corpus has been processed: 1 documents, 34 paragraphs, 34 sentences, 541 tokens\n",
      "Save corpus\n",
      "[=] 34                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 63: индастриал-метал != индастриал\n",
      "token 63: индастриал-метал != индастриал\n",
      "token 73 (-) is not found\n",
      "token 73 (-) is not found\n",
      "token 74 (метал) is not found\n",
      "token 74 (метал) is not found\n",
      "token 108:  != für\n",
      "token 108:  != für\n",
      "token 63: индастриал-метал != индастриал\n",
      "token 63: индастриал-метал != индастриал\n",
      "token 73 (-) is not found\n",
      "token 73 (-) is not found\n",
      "token 74 (метал) is not found\n",
      "token 74 (метал) is not found\n",
      "token 302:  != für\n",
      "token 302:  != für\n",
      "\n",
      "264: _dataset/rucoref/rucoref_texts/OFC/64.txt\n",
      "Load corpus\n",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 541 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 76587.72it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 34/34 [00:00<00:00, 123575.68it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 541 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 34                                                           \n",
      "Corpus has been loaded: 34 sentences, 541 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "265: _dataset/rucoref/rucoref_texts/OFC/65.txt\n",
      "Load corpus\n",
      "[=] 57                                                           \n",
      "Corpus has been loaded: 57 sentences, 723 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 57/57 [00:00<00:00, 519728.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 57                                                           \n",
      "Corpus has been processed: 1 documents, 57 paragraphs, 57 sentences, 723 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 57                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 57/57 [00:00<00:00, 188694.02it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 57                                                           \n",
      "Corpus has been loaded: 57 sentences, 723 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 57                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 57                                                           \n",
      "Corpus has been loaded: 57 sentences, 723 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 2745: какое-то != какое\n",
      "token 2745: какое-то != какое\n",
      "token 2750 (-) is not found\n",
      "token 2750 (-) is not found\n",
      "token 2751 (то) is not found\n",
      "token 2751 (то) is not found\n",
      "\n",
      "266: _dataset/rucoref/rucoref_texts/OFC/66.txt\n",
      "Load corpus\n",
      "[=] 56                                                           \n",
      "Corpus has been loaded: 56 sentences, 881 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 56/56 [00:00<00:00, 300743.95it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 56                                                           \n",
      "Corpus has been processed: 1 documents, 53 paragraphs, 56 sentences, 881 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 56                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 56/56 [00:00<00:00, 209528.12it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 56                                                           \n",
      "Corpus has been loaded: 56 sentences, 881 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 56                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 56                                                           \n",
      "Corpus has been loaded: 56 sentences, 881 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 2: Сан-Франциско != Сан\n",
      "token 2: Сан-Франциско != Сан\n",
      "token 5 (-) is not found\n",
      "token 5 (-) is not found\n",
      "token 6 (Франциско) is not found\n",
      "token 6 (Франциско) is not found\n",
      "token 220: Сан-Франциско != Сан\n",
      "token 220: Сан-Франциско != Сан\n",
      "token 223 (-) is not found\n",
      "token 223 (-) is not found\n",
      "token 224 (Франциско) is not found\n",
      "token 224 (Франциско) is not found\n",
      "\n",
      "267: _dataset/rucoref/rucoref_texts/OFC/67.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 83                                                           \n",
      "Corpus has been loaded: 83 sentences, 1401 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/83 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 83                                                           \n",
      "Corpus has been processed: 1 documents, 83 paragraphs, 83 sentences, 1401 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 83                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 83/83 [00:00<00:00, 223.18it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 83/83 [00:00<00:00, 209.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 83                                                           \n",
      "Corpus has been loaded: 83 sentences, 1401 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 83                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 83                                                           \n",
      "Corpus has been loaded: 83 sentences, 1401 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "268: _dataset/rucoref/rucoref_texts/OFC/68.txt\n",
      "Load corpus\n",
      "[=] 147                                                           \n",
      "Corpus has been loaded: 147 sentences, 3204 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/147 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 147                                                           \n",
      "Corpus has been processed: 1 documents, 144 paragraphs, 147 sentences, 3204 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 147                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 147/147 [00:00<00:00, 154.28it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 147/147 [00:00<00:00, 153.34it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 147                                                           \n",
      "Corpus has been loaded: 147 sentences, 3204 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 147                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 147                                                           \n",
      "Corpus has been loaded: 147 sentences, 3204 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 431: Премьер-лиги != Премьер\n",
      "token 431: Премьер-лиги != Премьер\n",
      "token 438 (-) is not found\n",
      "token 438 (-) is not found\n",
      "token 439 (лиги) is not found\n",
      "token 439 (лиги) is not found\n",
      "token 1985: L != L&YR\n",
      "token 1985: L != L&YR\n",
      "token 1990: F. != F.C\n",
      "token 1990: F. != F.C\n",
      "token 11394: Премьер-лигу != Премьер\n",
      "token 11394: Премьер-лигу != Премьер\n",
      "token 11401 (-) is not found\n",
      "token 11401 (-) is not found\n",
      "token 11402 (лигу) is not found\n",
      "token 11402 (лигу) is not found\n",
      "token 12170: Премьер-лигу != Премьер\n",
      "token 12170: Премьер-лигу != Премьер\n",
      "token 12177 (-) is not found\n",
      "token 12177 (-) is not found\n",
      "token 12178 (лигу) is not found\n",
      "token 12178 (лигу) is not found\n",
      "token 12824: Премьер-лигу != Премьер\n",
      "token 12824: Премьер-лигу != Премьер\n",
      "token 12831 (-) is not found\n",
      "token 12831 (-) is not found\n",
      "token 12832 (лигу) is not found\n",
      "token 12832 (лигу) is not found\n",
      "token 12998: Премьер-лигу != Премьер\n",
      "token 12998: Премьер-лигу != Премьер\n",
      "token 13005 (-) is not found\n",
      "token 13005 (-) is not found\n",
      "token 13006 (лигу) is not found\n",
      "token 13006 (лигу) is not found\n",
      "token 13315: Премьер-лиге != Премьер\n",
      "token 13315: Премьер-лиге != Премьер\n",
      "token 13322 (-) is not found\n",
      "token 13322 (-) is not found\n",
      "token 13323 (лиге) is not found\n",
      "token 13323 (лиге) is not found\n",
      "token 13418: Премьер-лиги != Премьер\n",
      "token 13418: Премьер-лиги != Премьер\n",
      "token 13425 (-) is not found\n",
      "token 13425 (-) is not found\n",
      "token 13426 (лиги) is not found\n",
      "token 13426 (лиги) is not found\n",
      "token 17544 (») is not found\n",
      "token 17544 (») is not found\n",
      "token 17544 (») is not found\n",
      "token 17544 (») is not found\n",
      "\n",
      "269: _dataset/rucoref/rucoref_texts/OFC/69.txt\n",
      "Load corpus\n",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 653 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 36/36 [00:00<00:00, 74198.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been processed: 1 documents, 36 paragraphs, 36 sentences, 653 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 36/36 [00:00<00:00, 164661.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 653 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 36                                                           \n",
      "Corpus has been loaded: 36 sentences, 653 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 174: либерал-демократы != либерал\n",
      "token 174: либерал-демократы != либерал\n",
      "token 181 (-) is not found\n",
      "token 181 (-) is not found\n",
      "token 182 (демократы) is not found\n",
      "token 182 (демократы) is not found\n",
      "token 1231: Либерал-демократы != Либерал\n",
      "token 1231: Либерал-демократы != Либерал\n",
      "token 1238 (-) is not found\n",
      "token 1238 (-) is not found\n",
      "token 1239 (демократы) is not found\n",
      "token 1239 (демократы) is not found\n",
      "token 1475: Либерал-демократы != Либерал\n",
      "token 1475: Либерал-демократы != Либерал\n",
      "token 1482 (-) is not found\n",
      "token 1482 (-) is not found\n",
      "token 1483 (демократы) is not found\n",
      "token 1483 (демократы) is not found\n",
      "token 2013: Либерал-демократы != Либерал\n",
      "token 2013: Либерал-демократы != Либерал\n",
      "token 2020 (-) is not found\n",
      "token 2020 (-) is not found\n",
      "token 2021 (демократы) is not found\n",
      "token 2021 (демократы) is not found\n",
      "token 3077: либерал-демократами != либерал\n",
      "token 3077: либерал-демократами != либерал\n",
      "token 3084 (-) is not found\n",
      "token 3084 (-) is not found\n",
      "token 3085 (демократами) is not found\n",
      "token 3085 (демократами) is not found\n",
      "\n",
      "270: _dataset/rucoref/rucoref_texts/OFC/70.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 139                                                           \n",
      "Corpus has been loaded: 139 sentences, 1749 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/139 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 139                                                           \n",
      "Corpus has been processed: 1 documents, 136 paragraphs, 139 sentences, 1749 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 139                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 139/139 [00:00<00:00, 239.00it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 139/139 [00:00<00:00, 228.19it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 139                                                           \n",
      "Corpus has been loaded: 139 sentences, 1749 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 139                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 139                                                           \n",
      "Corpus has been loaded: 139 sentences, 1749 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "271: _dataset/rucoref/rucoref_texts/OFC/71.txt\n",
      "Load corpus\n",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 613 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 25/25 [00:00<00:00, 65782.69it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been processed: 1 documents, 24 paragraphs, 25 sentences, 613 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 25/25 [00:00<00:00, 86019.36it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 613 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 25                                                           \n",
      "Corpus has been loaded: 25 sentences, 613 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1215: Санкт-Петербурге != Санкт\n",
      "token 1215: Санкт-Петербурге != Санкт\n",
      "token 1220 (-) is not found\n",
      "token 1220 (-) is not found\n",
      "token 1221 (Петербурге) is not found\n",
      "token 1221 (Петербурге) is not found\n",
      "token 1458: Санкт-Петербурга != Санкт\n",
      "token 1458: Санкт-Петербурга != Санкт\n",
      "token 1463 (-) is not found\n",
      "token 1463 (-) is not found\n",
      "token 1464 (Петербурга) is not found\n",
      "token 1464 (Петербурга) is not found\n",
      "token 1593: Санкт-Петербурге != Санкт\n",
      "token 1593: Санкт-Петербурге != Санкт\n",
      "token 1599 (Петербурге) is not found\n",
      "token 1599 (Петербурге) is not found\n",
      "token 1835: Санкт-Петербурге != Санкт\n",
      "token 1835: Санкт-Петербурге != Санкт\n",
      "token 1840 (-) is not found\n",
      "token 1840 (-) is not found\n",
      "token 1841 (Петербурге) is not found\n",
      "token 1841 (Петербурге) is not found\n",
      "token 2457 (—) is not found\n",
      "token 2457 (—) is not found\n",
      "token 2459: 24-летних != 24\n",
      "token 2459: 24-летних != 24\n",
      "token 2461 (-) is not found\n",
      "token 2461 (-) is not found\n",
      "token 2462 (летних) is not found\n",
      "token 2462 (летних) is not found\n",
      "token 3478 (—) is not found\n",
      "token 3478 (—) is not found\n",
      "\n",
      "272: _dataset/rucoref/rucoref_texts/OFC/72.txt\n",
      "Load corpus\n",
      "[=] 88                                                           \n",
      "Corpus has been loaded: 88 sentences, 1690 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been processed: 1 documents, 86 paragraphs, 88 sentences, 1690 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 164.43it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 88/88 [00:00<00:00, 160.71it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been loaded: 88 sentences, 1690 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been loaded: 88 sentences, 1690 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "275: _dataset/rucoref/rucoref_texts/OFC/75.txt\n",
      "Load corpus\n",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 1160 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 42/42 [00:00<00:00, 159277.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been processed: 1 documents, 39 paragraphs, 42 sentences, 1160 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 42/42 [00:00<00:00, 367001.60it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 1160 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 42                                                           \n",
      "Corpus has been loaded: 42 sentences, 1160 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 0: Пресс-секретарь != Пресс\n",
      "token 0: Пресс-секретарь != Пресс\n",
      "token 5 (-) is not found\n",
      "token 5 (-) is not found\n",
      "token 6 (секретарь) is not found\n",
      "token 6 (секретарь) is not found\n",
      "token 677: пресс-секретарь != пресс\n",
      "token 677: пресс-секретарь != пресс\n",
      "token 682 (-) is not found\n",
      "token 682 (-) is not found\n",
      "token 683 (секретарь) is not found\n",
      "token 683 (секретарь) is not found\n",
      "token 2184: CC-BY != CC\n",
      "token 2184: CC-BY != CC\n",
      "token 2186 (-) is not found\n",
      "token 2186 (-) is not found\n",
      "token 2187 (BY) is not found\n",
      "token 2187 (BY) is not found\n",
      "token 2189 (-) is not found\n",
      "token 2189 (-) is not found\n",
      "token 2190: -SA != SA\n",
      "token 2190: -SA != SA\n",
      "token 3214: CC-BY != CC\n",
      "token 3214: CC-BY != CC\n",
      "token 3216 (-) is not found\n",
      "token 3216 (-) is not found\n",
      "token 3217 (BY) is not found\n",
      "token 3217 (BY) is not found\n",
      "token 3219 (-) is not found\n",
      "token 3219 (-) is not found\n",
      "token 3220: -SA != SA\n",
      "token 3220: -SA != SA\n",
      "token 3279: CC-BY != CC\n",
      "token 3279: CC-BY != CC\n",
      "token 3281 (-) is not found\n",
      "token 3281 (-) is not found\n",
      "token 3282 (BY) is not found\n",
      "token 3282 (BY) is not found\n",
      "token 3284 (-) is not found\n",
      "token 3284 (-) is not found\n",
      "token 3285: -SA != SA\n",
      "token 3285: -SA != SA\n",
      "token 4790: CC-BY != CC\n",
      "token 4790: CC-BY != CC\n",
      "token 4792 (-) is not found\n",
      "token 4792 (-) is not found\n",
      "token 4793 (BY) is not found\n",
      "token 4793 (BY) is not found\n",
      "token 4795 (-) is not found\n",
      "token 4795 (-) is not found\n",
      "token 4796: -SA != SA\n",
      "token 4796: -SA != SA\n",
      "token 5357: CC-BY != CC\n",
      "token 5357: CC-BY != CC\n",
      "token 5359 (-) is not found\n",
      "token 5359 (-) is not found\n",
      "token 5360 (BY) is not found\n",
      "token 5360 (BY) is not found\n",
      "token 5362 (-) is not found\n",
      "token 5362 (-) is not found\n",
      "token 5363: -SA != SA\n",
      "token 5363: -SA != SA\n",
      "token 5517: CC-BY != CC\n",
      "token 5517: CC-BY != CC\n",
      "token 5519 (-) is not found\n",
      "token 5519 (-) is not found\n",
      "token 5520 (BY) is not found\n",
      "token 5520 (BY) is not found\n",
      "token 5522 (-) is not found\n",
      "token 5522 (-) is not found\n",
      "token 5523: -SA != SA\n",
      "token 5523: -SA != SA\n",
      "token 5703: CC-BY != CC\n",
      "token 5703: CC-BY != CC\n",
      "token 5705 (-) is not found\n",
      "token 5705 (-) is not found\n",
      "token 5706 (BY) is not found\n",
      "token 5706 (BY) is not found\n",
      "token 5708 (-) is not found\n",
      "token 5708 (-) is not found\n",
      "token 5709: -SA != SA\n",
      "token 5709: -SA != SA\n",
      "\n",
      "277: _dataset/rucoref/rucoref_texts/OFC/77.txt\n",
      "Load corpus\n",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 430 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 206277.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been processed: 1 documents, 23 paragraphs, 24 sentences, 430 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 202135.13it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 430 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 430 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 361: Коста-Рика != Коста\n",
      "token 361: Коста-Рика != Коста\n",
      "token 366 (-) is not found\n",
      "token 366 (-) is not found\n",
      "token 367 (Рика) is not found\n",
      "token 367 (Рика) is not found\n",
      "token 1789: Коста != Коста.Рика\n",
      "token 1789: Коста != Коста.Рика\n",
      "\n",
      "279: _dataset/rucoref/rucoref_texts/OFC/79.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 107                                                           \n",
      "Corpus has been loaded: 107 sentences, 2591 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/107 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 107                                                           \n",
      "Corpus has been processed: 1 documents, 100 paragraphs, 107 sentences, 2591 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 107                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 107/107 [00:00<00:00, 173.96it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 107/107 [00:00<00:00, 174.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 107                                                           \n",
      "Corpus has been loaded: 107 sentences, 2591 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 107                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 107                                                           \n",
      "Corpus has been loaded: 107 sentences, 2591 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 0: Фри-джаз != Фри\n",
      "token 0: Фри-джаз != Фри\n",
      "token 3 (-) is not found\n",
      "token 3 (-) is not found\n",
      "token 4 (джаз) is not found\n",
      "token 4 (джаз) is not found\n",
      "token 586: фри-джаза != фри\n",
      "token 586: фри-джаза != фри\n",
      "token 589 (-) is not found\n",
      "token 589 (-) is not found\n",
      "token 590 (джаза) is not found\n",
      "token 590 (джаза) is not found\n",
      "token 833: Фри-джаз != Фри\n",
      "token 833: Фри-джаз != Фри\n",
      "token 836 (-) is not found\n",
      "token 836 (-) is not found\n",
      "token 837 (джаз) is not found\n",
      "token 837 (джаз) is not found\n",
      "token 1052: фри-джаза != фри\n",
      "token 1052: фри-джаза != фри\n",
      "token 1055 (-) is not found\n",
      "token 1055 (-) is not found\n",
      "token 1056 (джаза) is not found\n",
      "token 1056 (джаза) is not found\n",
      "token 1293: фри-джаза != фри\n",
      "token 1293: фри-джаза != фри\n",
      "token 1296 (-) is not found\n",
      "token 1296 (-) is not found\n",
      "token 1297 (джаза) is not found\n",
      "token 1297 (джаза) is not found\n",
      "token 1537: фри-джаз != фри\n",
      "token 1537: фри-джаз != фри\n",
      "token 1540 (-) is not found\n",
      "token 1540 (-) is not found\n",
      "token 1541 (джаз) is not found\n",
      "token 1541 (джаз) is not found\n",
      "token 1826: Фри-джаз != Фри\n",
      "token 1826: Фри-джаз != Фри\n",
      "token 1830 (джаз) is not found\n",
      "token 1830 (джаз) is not found\n",
      "token 1918: фри-джазом != фри\n",
      "token 1918: фри-джазом != фри\n",
      "token 1921 (-) is not found\n",
      "token 1921 (-) is not found\n",
      "token 1922 (джазом) is not found\n",
      "token 1922 (джазом) is not found\n",
      "token 1952: фри-джазом != фри\n",
      "token 1952: фри-джазом != фри\n",
      "token 1956 (джазом) is not found\n",
      "token 1956 (джазом) is not found\n",
      "token 2204: фри-джаза != фри\n",
      "token 2204: фри-джаза != фри\n",
      "token 2207 (-) is not found\n",
      "token 2207 (-) is not found\n",
      "token 2208 (джаза) is not found\n",
      "token 2208 (джаза) is not found\n",
      "token 2204: фри-джаза != фри\n",
      "token 2204: фри-джаза != фри\n",
      "token 2207 (-) is not found\n",
      "token 2207 (-) is not found\n",
      "token 2208 (джаза) is not found\n",
      "token 2208 (джаза) is not found\n",
      "token 2270: фри-джаза != фри\n",
      "token 2270: фри-джаза != фри\n",
      "token 2273 (-) is not found\n",
      "token 2273 (-) is not found\n",
      "token 2274 (джаза) is not found\n",
      "token 2274 (джаза) is not found\n",
      "token 2727: фри-джаз != фри\n",
      "token 2727: фри-джаз != фри\n",
      "token 2730 (-) is not found\n",
      "token 2730 (-) is not found\n",
      "token 2731 (джаз) is not found\n",
      "token 2731 (джаз) is not found\n",
      "token 2911: фри-джазе != фри\n",
      "token 2911: фри-джазе != фри\n",
      "token 2914 (-) is not found\n",
      "token 2914 (-) is not found\n",
      "token 2915 (джазе) is not found\n",
      "token 2915 (джазе) is not found\n",
      "token 3342: фри-джазе != фри\n",
      "token 3342: фри-джазе != фри\n",
      "token 3345 (-) is not found\n",
      "token 3345 (-) is not found\n",
      "token 3346 (джазе) is not found\n",
      "token 3346 (джазе) is not found\n",
      "token 3469: фри-джазе != фри\n",
      "token 3469: фри-джазе != фри\n",
      "token 3472 (-) is not found\n",
      "token 3472 (-) is not found\n",
      "token 3473 (джазе) is not found\n",
      "token 3473 (джазе) is not found\n",
      "token 4054: фри-джаз != фри\n",
      "token 4054: фри-джаз != фри\n",
      "token 4057 (-) is not found\n",
      "token 4057 (-) is not found\n",
      "token 4058 (джаз) is not found\n",
      "token 4058 (джаз) is not found\n",
      "token 4086: Фри-джаз != Фри\n",
      "token 4086: Фри-джаз != Фри\n",
      "token 4090 (джаз) is not found\n",
      "token 4090 (джаз) is not found\n",
      "token 5199: фри-джаза != фри\n",
      "token 5199: фри-джаза != фри\n",
      "token 5202 (-) is not found\n",
      "token 5202 (-) is not found\n",
      "token 5203 (джаза) is not found\n",
      "token 5203 (джаза) is not found\n",
      "token 6485: фри-джаза != фри\n",
      "token 6485: фри-джаза != фри\n",
      "token 6488 (-) is not found\n",
      "token 6488 (-) is not found\n",
      "token 6489 (джаза) is not found\n",
      "token 6489 (джаза) is not found\n",
      "token 6980: Нью-Йорк != Нью\n",
      "token 6980: Нью-Йорк != Нью\n",
      "token 6983 (-) is not found\n",
      "token 6983 (-) is not found\n",
      "token 6984 (Йорк) is not found\n",
      "token 6984 (Йорк) is not found\n",
      "token 7483: фри-джаза != фри\n",
      "token 7483: фри-джаза != фри\n",
      "token 7486 (-) is not found\n",
      "token 7486 (-) is not found\n",
      "token 7487 (джаза) is not found\n",
      "token 7487 (джаза) is not found\n",
      "token 7683: Composer != Composer’s\n",
      "token 7683: Composer != Composer’s\n",
      "token 7836: фри-джаз != фри\n",
      "token 7836: фри-джаз != фри\n",
      "token 7839 (-) is not found\n",
      "token 7839 (-) is not found\n",
      "token 7840 (джаз) is not found\n",
      "token 7840 (джаз) is not found\n",
      "token 9425: фри-джаза != фри\n",
      "token 9425: фри-джаза != фри\n",
      "token 9428 (-) is not found\n",
      "token 9428 (-) is not found\n",
      "token 9429 (джаза) is not found\n",
      "token 9429 (джаза) is not found\n",
      "token 9875: фри-джаз != фри\n",
      "token 9875: фри-джаз != фри\n",
      "token 9878 (-) is not found\n",
      "token 9878 (-) is not found\n",
      "token 9879 (джаз) is not found\n",
      "token 9879 (джаз) is not found\n",
      "token 10020: фри-джаза != фри\n",
      "token 10020: фри-джаза != фри\n",
      "token 10023 (-) is not found\n",
      "token 10023 (-) is not found\n",
      "token 10024 (джаза) is not found\n",
      "token 10024 (джаза) is not found\n",
      "token 10893: фри-джаза != фри\n",
      "token 10893: фри-джаза != фри\n",
      "token 10896 (-) is not found\n",
      "token 10896 (-) is not found\n",
      "token 10897 (джаза) is not found\n",
      "token 10897 (джаза) is not found\n",
      "token 11067: Нью-Йорке != Нью\n",
      "token 11067: Нью-Йорке != Нью\n",
      "token 11070 (-) is not found\n",
      "token 11070 (-) is not found\n",
      "token 11071 (Йорке) is not found\n",
      "token 11071 (Йорке) is not found\n",
      "token 11693: фри-джаза != фри\n",
      "token 11693: фри-джаза != фри\n",
      "token 11696 (-) is not found\n",
      "token 11696 (-) is not found\n",
      "token 11697 (джаза) is not found\n",
      "token 11697 (джаза) is not found\n",
      "token 11903: фри-джазе != фри\n",
      "token 11903: фри-джазе != фри\n",
      "token 11906 (-) is not found\n",
      "token 11906 (-) is not found\n",
      "token 11907 (джазе) is not found\n",
      "token 11907 (джазе) is not found\n",
      "token 11903: фри-джазе != фри\n",
      "token 11903: фри-джазе != фри\n",
      "token 11906 (-) is not found\n",
      "token 11906 (-) is not found\n",
      "token 11907 (джазе) is not found\n",
      "token 11907 (джазе) is not found\n",
      "token 12281: фри-джаза != фри\n",
      "token 12281: фри-джаза != фри\n",
      "token 12284 (-) is not found\n",
      "token 12284 (-) is not found\n",
      "token 12285 (джаза) is not found\n",
      "token 12285 (джаза) is not found\n",
      "token 12444: Е. != Е\n",
      "token 12444: Е. != Е\n",
      "token 12445 (.) is not found\n",
      "token 12445 (.) is not found\n",
      "token 12447: С. != С\n",
      "token 12447: С. != С\n",
      "token 12448 (.) is not found\n",
      "token 12448 (.) is not found\n",
      "token 12735: фри-джаза != фри\n",
      "token 12735: фри-джаза != фри\n",
      "token 12738 (-) is not found\n",
      "token 12738 (-) is not found\n",
      "token 12739 (джаза) is not found\n",
      "token 12739 (джаза) is not found\n",
      "token 12885: фри-джаз != фри\n",
      "token 12885: фри-джаз != фри\n",
      "token 12888 (-) is not found\n",
      "token 12888 (-) is not found\n",
      "token 12889 (джаз) is not found\n",
      "token 12889 (джаз) is not found\n",
      "token 13207: Фри-джазу != Фри\n",
      "token 13207: Фри-джазу != Фри\n",
      "token 13210 (-) is not found\n",
      "token 13210 (-) is not found\n",
      "token 13211 (джазу) is not found\n",
      "token 13211 (джазу) is not found\n",
      "token 14287: фри-джаза != фри\n",
      "token 14287: фри-джаза != фри\n",
      "token 14291 (джаза) is not found\n",
      "token 14291 (джаза) is not found\n",
      "token 14572: фри-джаза != фри\n",
      "token 14572: фри-джаза != фри\n",
      "token 14575 (-) is not found\n",
      "token 14575 (-) is not found\n",
      "token 14576 (джаза) is not found\n",
      "token 14576 (джаза) is not found\n",
      "token 14858: фри-джаз != фри\n",
      "token 14858: фри-джаз != фри\n",
      "token 14861 (-) is not found\n",
      "token 14861 (-) is not found\n",
      "token 14862 (джаз) is not found\n",
      "token 14862 (джаз) is not found\n",
      "token 15757: Фри-джаз != Фри\n",
      "token 15757: Фри-джаз != Фри\n",
      "token 15760 (-) is not found\n",
      "token 15760 (-) is not found\n",
      "token 15761 (джаз) is not found\n",
      "token 15761 (джаз) is not found\n",
      "token 0: Фри-джаз != Фри\n",
      "token 0: Фри-джаз != Фри\n",
      "token 3 (-) is not found\n",
      "token 3 (-) is not found\n",
      "token 4 (джаз) is not found\n",
      "token 4 (джаз) is not found\n",
      "token 1052: фри-джаза != фри\n",
      "token 1052: фри-джаза != фри\n",
      "token 1055 (-) is not found\n",
      "token 1055 (-) is not found\n",
      "token 1056 (джаза) is not found\n",
      "token 1056 (джаза) is not found\n",
      "token 2204: фри-джаза != фри\n",
      "token 2204: фри-джаза != фри\n",
      "token 2207 (-) is not found\n",
      "token 2207 (-) is not found\n",
      "token 2208 (джаза) is not found\n",
      "token 2208 (джаза) is not found\n",
      "\n",
      "280: _dataset/rucoref/rucoref_texts/OFC/80.txt\n",
      "Load corpus\n",
      "[=] 48                                                           \n",
      "Corpus has been loaded: 48 sentences, 763 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 48/48 [00:00<00:00, 110740.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 48                                                           \n",
      "Corpus has been processed: 1 documents, 48 paragraphs, 48 sentences, 763 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 48                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 48/48 [00:00<00:00, 420306.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 48                                                           \n",
      "Corpus has been loaded: 48 sentences, 763 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 48                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 48                                                           \n",
      "Corpus has been loaded: 48 sentences, 763 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "282: _dataset/rucoref/rucoref_texts/OFC/82.txt\n",
      "Load corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 385 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 93103.31it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 117983.23it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been processed: 1 documents, 20 paragraphs, 20 sentences, 385 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 385 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 385 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 41: Giove-A != Giove\n",
      "token 41: Giove-A != Giove\n",
      "token 46 (-) is not found\n",
      "token 46 (-) is not found\n",
      "token 47 (A) is not found\n",
      "token 47 (A) is not found\n",
      "token 154: Giove-A != Giove\n",
      "token 154: Giove-A != Giove\n",
      "token 159 (-) is not found\n",
      "token 159 (-) is not found\n",
      "token 160 (A) is not found\n",
      "token 160 (A) is not found\n",
      "token 174: GSTB-V2 != GSTB\n",
      "token 174: GSTB-V2 != GSTB\n",
      "token 178 (-) is not found\n",
      "token 178 (-) is not found\n",
      "token 179 (V2/A) is not found\n",
      "token 179 (V2/A) is not found\n",
      "token 229: Giove-A != Giove\n",
      "token 229: Giove-A != Giove\n",
      "token 234 (-) is not found\n",
      "token 234 (-) is not found\n",
      "token 235 (A) is not found\n",
      "token 235 (A) is not found\n",
      "token 531: Giove-A != Giove\n",
      "token 531: Giove-A != Giove\n",
      "token 536 (-) is not found\n",
      "token 536 (-) is not found\n",
      "token 537 (A) is not found\n",
      "token 537 (A) is not found\n",
      "token 2409 (») is not found\n",
      "token 2409 (») is not found\n",
      "\n",
      "288: _dataset/rucoref/rucoref_texts/OFC/88.txt\n",
      "Load corpus\n",
      "[=] 144                                                           \n",
      "Corpus has been loaded: 144 sentences, 2179 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/144 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 144                                                           \n",
      "Corpus has been processed: 1 documents, 142 paragraphs, 144 sentences, 2179 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 144                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 144/144 [00:00<00:00, 179.57it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 144/144 [00:00<00:00, 178.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 144                                                           \n",
      "Corpus has been loaded: 144 sentences, 2179 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 144                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 144                                                           \n",
      "Corpus has been loaded: 144 sentences, 2179 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 44: ток-шоу != ток\n",
      "token 44: ток-шоу != ток\n",
      "token 47 (-) is not found\n",
      "token 47 (-) is not found\n",
      "token 48 (шоу) is not found\n",
      "token 48 (шоу) is not found\n",
      "token 719: ток-шоу != ток\n",
      "token 719: ток-шоу != ток\n",
      "token 722 (-) is not found\n",
      "token 722 (-) is not found\n",
      "token 723 (шоу) is not found\n",
      "token 723 (шоу) is not found\n",
      "token 3866: ток-шоу != ток\n",
      "token 3866: ток-шоу != ток\n",
      "token 3869 (-) is not found\n",
      "token 3869 (-) is not found\n",
      "token 3870 (шоу) is not found\n",
      "token 3870 (шоу) is not found\n",
      "token 4215: ток-шоу != ток\n",
      "token 4215: ток-шоу != ток\n",
      "token 4218 (-) is not found\n",
      "token 4218 (-) is not found\n",
      "token 4219 (шоу) is not found\n",
      "token 4219 (шоу) is not found\n",
      "\n",
      "290: _dataset/rucoref/rucoref_texts/OFC/90.txt\n",
      "Load corpus\n",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 660 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 23/23 [00:00<00:00, 54471.48it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been processed: 1 documents, 21 paragraphs, 23 sentences, 660 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 23/23 [00:00<00:00, 78239.25it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 660 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 23                                                           \n",
      "Corpus has been loaded: 23 sentences, 660 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 378: russian-untouchables != russian\n",
      "token 378: russian-untouchables != russian\n",
      "token 385 (-) is not found\n",
      "token 385 (-) is not found\n",
      "token 386 (untouchables.com) is not found\n",
      "token 386 (untouchables.com) is not found\n",
      "token 2205 (—) is not found\n",
      "token 2205 (—) is not found\n",
      "\n",
      "295: _dataset/rucoref/rucoref_texts/OFC/95.txt\n",
      "Load corpus\n",
      "[=] 43                                                           \n",
      "Corpus has been loaded: 43 sentences, 1136 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 43/43 [00:00<00:00, 110444.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 43                                                           \n",
      "Corpus has been processed: 1 documents, 39 paragraphs, 43 sentences, 1136 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 43                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 43/43 [00:00<00:00, 362158.78it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 43                                                           \n",
      "Corpus has been loaded: 43 sentences, 1136 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 43                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 43                                                           \n",
      "Corpus has been loaded: 43 sentences, 1136 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "300: _dataset/rucoref/rucoref_texts/OFC/100.txt\n",
      "Load corpus\n",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 298 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 10/10 [00:00<00:00, 80971.12it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 10/10 [00:00<00:00, 38621.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 10 sentences, 298 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 298 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 298 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "301: _dataset/rucoref/rucoref_texts/OFC/101.txt\n",
      "Load corpus\n",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1216 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 60/60 [00:00<00:00, 486766.42it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been processed: 1 documents, 57 paragraphs, 60 sentences, 1216 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 60/60 [00:00<00:00, 157878.44it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1216 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1216 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1379 (—) is not found\n",
      "token 1379 (—) is not found\n",
      "token 3458: пресс-конференции != пресс\n",
      "token 3458: пресс-конференции != пресс\n",
      "token 3463 (-) is not found\n",
      "token 3463 (-) is not found\n",
      "token 3464 (конференции) is not found\n",
      "token 3464 (конференции) is not found\n",
      "token 4484: бизнес-модель != бизнес\n",
      "token 4484: бизнес-модель != бизнес\n",
      "token 4490 (-) is not found\n",
      "token 4490 (-) is not found\n",
      "token 4491 (модель) is not found\n",
      "token 4491 (модель) is not found\n",
      "token 6568: кто-то != кто\n",
      "token 6568: кто-то != кто\n",
      "token 6571 (-) is not found\n",
      "token 6571 (-) is not found\n",
      "token 6572 (то) is not found\n",
      "token 6572 (то) is not found\n",
      "\n",
      "302: _dataset/rucoref/rucoref_texts/OFC/102.txt\n",
      "Load corpus\n",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 955 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 37/37 [00:00<00:00, 145717.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been processed: 1 documents, 34 paragraphs, 37 sentences, 955 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 37/37 [00:00<00:00, 166690.92it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 955 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 37                                                           \n",
      "Corpus has been loaded: 37 sentences, 955 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 4290 (—) is not found\n",
      "token 4290 (—) is not found\n",
      "token 4292: 45-летних != 45\n",
      "token 4292: 45-летних != 45\n",
      "token 4294 (-) is not found\n",
      "token 4294 (-) is not found\n",
      "token 4295 (летних) is not found\n",
      "token 4295 (летних) is not found\n",
      "\n",
      "303: _dataset/rucoref/rucoref_texts/OFC/103.txt\n",
      "Load corpus\n",
      "[=] 50                                                           \n",
      "Corpus has been loaded: 50 sentences, 1676 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 50/50 [00:00<00:00, 423667.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been processed: 1 documents, 48 paragraphs, 50 sentences, 1676 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 50/50 [00:00<00:00, 183477.87it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been loaded: 50 sentences, 1676 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 50                                                           \n",
      "Corpus has been loaded: 50 sentences, 1676 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "306: _dataset/rucoref/rucoref_texts/OFC/106.txt\n",
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 329 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 41418.41it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 76725.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been processed: 1 documents, 15 paragraphs, 15 sentences, 329 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 329 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 329 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "310: _dataset/rucoref/rucoref_texts/OFC/110.txt\n",
      "Load corpus\n",
      "[=] 63                                                           \n",
      "Corpus has been loaded: 63 sentences, 1211 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 63/63 [00:00<00:00, 294912.00it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been processed: 1 documents, 60 paragraphs, 63 sentences, 1211 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 63/63 [00:00<00:00, 221122.30it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been loaded: 63 sentences, 1211 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 63                                                           \n",
      "Corpus has been loaded: 63 sentences, 1211 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "311: _dataset/rucoref/rucoref_texts/OFC/111.txt\n",
      "Load corpus\n",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 342 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 92351.65it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 24/24 [00:00<00:00, 136770.78it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been processed: 1 documents, 24 paragraphs, 24 sentences, 342 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 342 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 24                                                           \n",
      "Corpus has been loaded: 24 sentences, 342 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1626: премьер-министр != премьер\n",
      "token 1626: премьер-министр != премьер\n",
      "token 1633 (-) is not found\n",
      "token 1633 (-) is not found\n",
      "token 1634 (министр) is not found\n",
      "token 1634 (министр) is not found\n",
      "token 1651: аль-Гануши != аль\n",
      "token 1651: аль-Гануши != аль\n",
      "token 1654 (-) is not found\n",
      "token 1654 (-) is not found\n",
      "token 1655 (Гануши) is not found\n",
      "token 1655 (Гануши) is not found\n",
      "token 2109: премьер-министра != премьер\n",
      "token 2109: премьер-министра != премьер\n",
      "token 2116 (-) is not found\n",
      "token 2116 (-) is not found\n",
      "token 2117 (министра) is not found\n",
      "token 2117 (министра) is not found\n",
      "\n",
      "312: _dataset/rucoref/rucoref_texts/OFC/112.txt\n",
      "Load corpus\n",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 936 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 49/49 [00:00<00:00, 253104.55it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been processed: 1 documents, 45 paragraphs, 49 sentences, 936 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 49/49 [00:00<00:00, 136558.73it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 936 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 936 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 57: грузино-абхазского != грузино\n",
      "token 57: грузино-абхазского != грузино\n",
      "token 64 (-) is not found\n",
      "token 64 (-) is not found\n",
      "token 65 (абхазского) is not found\n",
      "token 65 (абхазского) is not found\n",
      "token 1018: премьер-министра != премьер\n",
      "token 1018: премьер-министра != премьер\n",
      "token 1025 (-) is not found\n",
      "token 1025 (-) is not found\n",
      "token 1026 (министра) is not found\n",
      "token 1026 (министра) is not found\n",
      "token 1273: грузино-абхазского != грузино\n",
      "token 1273: грузино-абхазского != грузино\n",
      "token 1280 (-) is not found\n",
      "token 1280 (-) is not found\n",
      "token 1281 (абхазского) is not found\n",
      "token 1281 (абхазского) is not found\n",
      "\n",
      "313: _dataset/rucoref/rucoref_texts/OFC/113.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 119                                                           \n",
      "Corpus has been loaded: 119 sentences, 2059 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/119 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 119                                                           \n",
      "Corpus has been processed: 1 documents, 119 paragraphs, 119 sentences, 2059 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 119                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 119/119 [00:00<00:00, 303.94it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 119/119 [00:00<00:00, 300.79it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 119                                                           \n",
      "Corpus has been loaded: 119 sentences, 2059 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 119                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 119                                                           \n",
      "Corpus has been loaded: 119 sentences, 2059 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "316: _dataset/rucoref/rucoref_texts/OFC/116.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 81                                                           \n",
      "Corpus has been loaded: 81 sentences, 1376 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/81 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 81                                                           \n",
      "Corpus has been processed: 1 documents, 80 paragraphs, 81 sentences, 1376 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 81                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 81/81 [00:00<00:00, 218.82it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 81/81 [00:00<00:00, 216.58it/s]\n",
      "token 1708: кому-то != кому\n",
      "token 1708: кому-то != кому\n",
      "token 1712 (-) is not found\n",
      "token 1712 (-) is not found\n",
      "token 1713 (то) is not found\n",
      "token 1713 (то) is not found\n",
      "\n",
      "318: _dataset/rucoref/rucoref_texts/OFC/118.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 81                                                           \n",
      "Corpus has been loaded: 81 sentences, 1376 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 81                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 81                                                           \n",
      "Corpus has been loaded: 81 sentences, 1376 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 302 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 122640.47it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 74191.70it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been processed: 1 documents, 15 paragraphs, 15 sentences, 302 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 302 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 302 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 19: протон-антипротонный != протон\n",
      "token 19: протон-антипротонный != протон\n",
      "token 25 (-) is not found\n",
      "token 25 (-) is not found\n",
      "token 26 (антипротонный) is not found\n",
      "token 26 (антипротонный) is not found\n",
      "token 1024: электрон-вольт != электрон\n",
      "token 1024: электрон-вольт != электрон\n",
      "token 1032 (-) is not found\n",
      "token 1032 (-) is not found\n",
      "token 1033 (вольт) is not found\n",
      "token 1033 (вольт) is not found\n",
      "\n",
      "319: _dataset/rucoref/rucoref_texts/OFC/119.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 579 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 79387.46it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 28 paragraphs, 30 sentences, 579 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 268865.64it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 579 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 579 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "320: _dataset/rucoref/rucoref_texts/OFC/120.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been loaded: 69 sentences, 1572 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/69 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been processed: 1 documents, 69 paragraphs, 69 sentences, 1572 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 69/69 [00:00<00:00, 129.72it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 69/69 [00:00<00:00, 129.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been loaded: 69 sentences, 1572 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 69                                                           \n",
      "Corpus has been loaded: 69 sentences, 1572 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 321: Чачба-Шервашидзе != Чачба\n",
      "token 321: Чачба-Шервашидзе != Чачба\n",
      "token 326 (-) is not found\n",
      "token 326 (-) is not found\n",
      "token 327 (Шервашидзе) is not found\n",
      "token 327 (Шервашидзе) is not found\n",
      "\n",
      "321: _dataset/rucoref/rucoref_texts/OFC/121.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 99                                                           \n",
      "Corpus has been loaded: 99 sentences, 1771 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/99 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 99                                                           \n",
      "Corpus has been processed: 1 documents, 97 paragraphs, 99 sentences, 1771 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 99                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:00<00:00, 250.61it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 99/99 [00:00<00:00, 247.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 99                                                           \n",
      "Corpus has been loaded: 99 sentences, 1771 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 99                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 99                                                           \n",
      "Corpus has been loaded: 99 sentences, 1771 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 165: генерал-майор != генерал\n",
      "token 165: генерал-майор != генерал\n",
      "token 172 (-) is not found\n",
      "token 172 (-) is not found\n",
      "token 173 (майор) is not found\n",
      "token 173 (майор) is not found\n",
      "token 6971:  != dodger_37\n",
      "token 6971:  != dodger_37\n",
      "\n",
      "322: _dataset/rucoref/rucoref_texts/OFC/122.txt\n",
      "Load corpus\n",
      "[=] 33                                                           \n",
      "Corpus has been loaded: 33 sentences, 702 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 33/33 [00:00<00:00, 280186.30it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been processed: 1 documents, 30 paragraphs, 33 sentences, 702 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 33/33 [00:00<00:00, 257750.53it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been loaded: 33 sentences, 702 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 33                                                           \n",
      "Corpus has been loaded: 33 sentences, 702 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "323: _dataset/rucoref/rucoref_texts/OFC/123.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been loaded: 174 sentences, 4509 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/174 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been processed: 1 documents, 166 paragraphs, 174 sentences, 4509 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 174/174 [00:01<00:00, 137.77it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 174/174 [00:01<00:00, 136.82it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been loaded: 174 sentences, 4509 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 174                                                           \n",
      "Corpus has been loaded: 174 sentences, 4509 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 103: рок-группы != рок\n",
      "token 103: рок-группы != рок\n",
      "token 106 (-) is not found\n",
      "token 106 (-) is not found\n",
      "token 107 (группы) is not found\n",
      "token 107 (группы) is not found\n",
      "token 103: рок-группы != рок\n",
      "token 103: рок-группы != рок\n",
      "token 106 (-) is not found\n",
      "token 106 (-) is not found\n",
      "token 107 (группы) is not found\n",
      "token 107 (группы) is not found\n",
      "token 9318: Got != Gotta\n",
      "token 9318: Got != Gotta\n",
      "token 12169 (<) is not found\n",
      "token 12169 (<) is not found\n",
      "token 12170:  != Песня\n",
      "token 12170:  != Песня\n",
      "token 12175 (>) is not found\n",
      "token 12175 (>) is not found\n",
      "token 23628: хит-параде != хит\n",
      "token 23628: хит-параде != хит\n",
      "token 23631 (-) is not found\n",
      "token 23631 (-) is not found\n",
      "token 23632 (параде) is not found\n",
      "token 23632 (параде) is not found\n",
      "\n",
      "324: _dataset/rucoref/rucoref_texts/OFC/124.txt\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 306 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 133683.00it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been processed: 1 documents, 16 paragraphs, 16 sentences, 306 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 157163.62it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 306 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 306 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 0: 22-летний != 22\n",
      "token 0: 22-летний != 22\n",
      "token 2 (-) is not found\n",
      "token 2 (-) is not found\n",
      "token 3 (летний) is not found\n",
      "token 3 (летний) is not found\n",
      "token 1225: 40-летнюю != 40\n",
      "token 1225: 40-летнюю != 40\n",
      "token 1227 (-) is not found\n",
      "token 1227 (-) is not found\n",
      "token 1228 (летнюю) is not found\n",
      "token 1228 (летнюю) is not found\n",
      "\n",
      "328: _dataset/rucoref/rucoref_texts/OFC/128.txt\n",
      "Load corpus\n",
      "[=] 19                                                           \n",
      "Corpus has been loaded: 19 sentences, 461 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 19/19 [00:00<00:00, 162305.04it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 19/19 [00:00<00:00, 52567.13it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been processed: 1 documents, 19 paragraphs, 19 sentences, 461 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been loaded: 19 sentences, 461 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been loaded: 19 sentences, 461 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "330: _dataset/rucoref/rucoref_texts/OFC/130.txt\n",
      "Load corpus\n",
      "[=] 35                                                           \n",
      "Corpus has been loaded: 35 sentences, 743 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 35/35 [00:00<00:00, 128434.51it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been processed: 1 documents, 35 paragraphs, 35 sentences, 743 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 35/35 [00:00<00:00, 93922.35it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been loaded: 35 sentences, 743 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 35                                                           \n",
      "Corpus has been loaded: 35 sentences, 743 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 1098: iPad- != iPad\n",
      "token 1098: iPad- != iPad\n",
      "token 1622: iPad- != iPad\n",
      "token 1622: iPad- != iPad\n",
      "token 2015: вице-президент != вице\n",
      "token 2015: вице-президент != вице\n",
      "token 2019 (-) is not found\n",
      "token 2019 (-) is not found\n",
      "token 2020 (президент) is not found\n",
      "token 2020 (президент) is not found\n",
      "token 3165: вице-президент != вице\n",
      "token 3165: вице-президент != вице\n",
      "token 3169 (-) is not found\n",
      "token 3169 (-) is not found\n",
      "token 3170 (президент) is not found\n",
      "token 3170 (президент) is not found\n",
      "\n",
      "332: _dataset/rucoref/rucoref_texts/OFC/132.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been loaded: 67 sentences, 1148 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been processed: 1 documents, 65 paragraphs, 67 sentences, 1148 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 142.91it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 67/67 [00:00<00:00, 141.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been loaded: 67 sentences, 1148 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been loaded: 67 sentences, 1148 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "336: _dataset/rucoref/rucoref_texts/OFC/136.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1213 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been processed: 1 documents, 103 paragraphs, 103 sentences, 1213 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 350.26it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 103/103 [00:00<00:00, 351.51it/s]\n",
      "token 3136: каким-то != каким"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1213 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1213 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 3136: каким-то != каким\n",
      "token 3141 (-) is not found\n",
      "token 3141 (-) is not found\n",
      "token 3142 (то) is not found\n",
      "token 3142 (то) is not found\n",
      "\n",
      "338: _dataset/rucoref/rucoref_texts/OFC/138.txt\n",
      "Load corpus\n",
      "[=] 71                                                           \n",
      "Corpus has been loaded: 71 sentences, 1319 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/71 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been processed: 1 documents, 69 paragraphs, 71 sentences, 1319 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 71/71 [00:00<00:00, 172.62it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 71/71 [00:00<00:00, 171.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been loaded: 71 sentences, 1319 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 71                                                           \n",
      "Corpus has been loaded: 71 sentences, 1319 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 3330: вице-президенту != вице\n",
      "token 3330: вице-президенту != вице\n",
      "token 3334 (-) is not found\n",
      "token 3334 (-) is not found\n",
      "token 3335 (президенту) is not found\n",
      "token 3335 (президенту) is not found\n",
      "token 4029: Аль-Каиды != Аль\n",
      "token 4029: Аль-Каиды != Аль\n",
      "token 4032 (-) is not found\n",
      "token 4032 (-) is not found\n",
      "token 4033 (Каиды) is not found\n",
      "token 4033 (Каиды) is not found\n",
      "token 5573: Аль-Каиды != Аль\n",
      "token 5573: Аль-Каиды != Аль\n",
      "token 5576 (-) is not found\n",
      "token 5576 (-) is not found\n",
      "token 5577 (Каиды) is not found\n",
      "token 5577 (Каиды) is not found\n",
      "token 5573: Аль-Каиды != Аль\n",
      "token 5573: Аль-Каиды != Аль\n",
      "token 5576 (-) is not found\n",
      "token 5576 (-) is not found\n",
      "token 5577 (Каиды) is not found\n",
      "token 5577 (Каиды) is not found\n",
      "token 7997: Аль-Каидой != Аль\n",
      "token 7997: Аль-Каидой != Аль\n",
      "token 8000 (-) is not found\n",
      "token 8000 (-) is not found\n",
      "token 8001 (Каидой) is not found\n",
      "token 8001 (Каидой) is not found\n",
      "\n",
      "339: _dataset/rucoref/rucoref_texts/OFC/139.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been loaded: 67 sentences, 1003 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/67 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been processed: 1 documents, 64 paragraphs, 67 sentences, 1003 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 67/67 [00:00<00:00, 121.11it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 67/67 [00:00<00:00, 119.89it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been loaded: 67 sentences, 1003 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 67                                                           \n",
      "Corpus has been loaded: 67 sentences, 1003 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 1498: Яндекс != Яндекс.Кошелек\n",
      "token 1498: Яндекс != Яндекс.Кошелек\n",
      "\n",
      "340: _dataset/rucoref/rucoref_texts/OFC/140.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 106                                                           \n",
      "Corpus has been loaded: 106 sentences, 1480 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/106 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 106                                                           \n",
      "Corpus has been processed: 1 documents, 101 paragraphs, 106 sentences, 1480 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 106                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106/106 [00:00<00:00, 301.99it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 106/106 [00:00<00:00, 313.16it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 106                                                           \n",
      "Corpus has been loaded: 106 sentences, 1480 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 106                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 106                                                           \n",
      "Corpus has been loaded: 106 sentences, 1480 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 878 (–) is not found\n",
      "token 878 (–) is not found\n",
      "token 1663 (—) is not found\n",
      "token 1663 (—) is not found\n",
      "token 1720 (—) is not found\n",
      "token 1720 (—) is not found\n",
      "token 3763 (—) is not found\n",
      "token 3763 (—) is not found\n",
      "token 5889: какого-то != какого\n",
      "token 5889: какого-то != какого\n",
      "token 5895 (-) is not found\n",
      "token 5895 (-) is not found\n",
      "token 5896 (то) is not found\n",
      "token 5896 (то) is not found\n",
      "token 6955: Nim != Nim's\n",
      "token 6955: Nim != Nim's\n",
      "token 8401 (») is not found\n",
      "token 8401 (») is not found\n",
      "\n",
      "342: _dataset/rucoref/rucoref_texts/OFC/142.txt\n",
      "Load corpus\n",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1041 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 60/60 [00:00<00:00, 251155.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been processed: 1 documents, 59 paragraphs, 60 sentences, 1041 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 60/60 [00:00<00:00, 250406.21it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1041 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 60                                                           \n",
      "Corpus has been loaded: 60 sentences, 1041 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 470: премьер-министр != премьер\n",
      "token 470: премьер-министр != премьер\n",
      "token 477 (-) is not found\n",
      "token 477 (-) is not found\n",
      "token 478 (министр) is not found\n",
      "token 478 (министр) is not found\n",
      "token 940: премьер-министром != премьер\n",
      "token 940: премьер-министром != премьер\n",
      "token 947 (-) is not found\n",
      "token 947 (-) is not found\n",
      "token 948 (министром) is not found\n",
      "token 948 (министром) is not found\n",
      "token 1424: премьер-министра != премьер\n",
      "token 1424: премьер-министра != премьер\n",
      "token 1431 (-) is not found\n",
      "token 1431 (-) is not found\n",
      "token 1432 (министра) is not found\n",
      "token 1432 (министра) is not found\n",
      "token 1867: премьер-министром != премьер\n",
      "token 1867: премьер-министром != премьер\n",
      "token 1874 (-) is not found\n",
      "token 1874 (-) is not found\n",
      "token 1875 (министром) is not found\n",
      "token 1875 (министром) is not found\n",
      "token 2120: премьер-министром != премьер\n",
      "token 2120: премьер-министром != премьер\n",
      "token 2127 (-) is not found\n",
      "token 2127 (-) is not found\n",
      "token 2128 (министром) is not found\n",
      "token 2128 (министром) is not found\n",
      "token 2662: премьер-министром != премьер\n",
      "token 2662: премьер-министром != премьер\n",
      "token 2669 (-) is not found\n",
      "token 2669 (-) is not found\n",
      "token 2670 (министром) is not found\n",
      "token 2670 (министром) is not found\n",
      "token 4220: премьер-министр != премьер\n",
      "token 4220: премьер-министр != премьер\n",
      "token 4227 (-) is not found\n",
      "token 4227 (-) is not found\n",
      "token 4228 (министр) is not found\n",
      "token 4228 (министр) is not found\n",
      "\n",
      "345: _dataset/rucoref/rucoref_texts/OFC/145.txt\n",
      "Load corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 265 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 13/13 [00:00<00:00, 31590.93it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 13/13 [00:00<00:00, 37219.08it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been processed: 1 documents, 13 paragraphs, 13 sentences, 265 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 265 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 265 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 52: Формулы-1 != Формулы\n",
      "token 52: Формулы-1 != Формулы\n",
      "token 59 (-) is not found\n",
      "token 59 (-) is not found\n",
      "token 60 (1) is not found\n",
      "token 60 (1) is not found\n",
      "token 1621: Формулы-1 != Формулы\n",
      "token 1621: Формулы-1 != Формулы\n",
      "token 1628 (-) is not found\n",
      "token 1628 (-) is not found\n",
      "token 1629 (1) is not found\n",
      "token 1629 (1) is not found\n",
      "\n",
      "700: _dataset/rucoref/rucoref_texts/newsru/sunna.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 298 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 44283.75it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 55136.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 14 sentences, 298 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 298 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 298 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "701: _dataset/rucoref/rucoref_texts/newsru/duma_time.txt\n",
      "Load corpus\n",
      "[=] 19                                                           \n",
      "Corpus has been loaded: 19 sentences, 374 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 19/19 [00:00<00:00, 52359.91it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 19/19 [00:00<00:00, 191566.77it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been processed: 1 documents, 10 paragraphs, 19 sentences, 374 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been loaded: 19 sentences, 374 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 19                                                           \n",
      "Corpus has been loaded: 19 sentences, 374 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "702: _dataset/rucoref/rucoref_texts/newsru/m_l_king.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 272 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 36269.46it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 141154.46it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 14 sentences, 272 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 272 tokens\n",
      "Save corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 272 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "710: _dataset/rucoref/rucoref_texts/lentaru/lentaru016.txt\n",
      "Load corpus\n",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 207 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 10/10 [00:00<00:00, 7891.45it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 10/10 [00:00<00:00, 38130.04it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 10 sentences, 207 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 207 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 10                                                           \n",
      "Corpus has been loaded: 10 sentences, 207 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "711: _dataset/rucoref/rucoref_texts/lentaru/lentaru005.txt\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 194 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 11/11 [00:00<00:00, 51898.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 11                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 11 sentences, 194 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 11                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 11/11 [00:00<00:00, 108814.49it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 194 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 11                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 194 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 166: 55-летний != 55\n",
      "token 166: 55-летний != 55\n",
      "token 168 (-) is not found\n",
      "token 168 (-) is not found\n",
      "token 169 (летний) is not found\n",
      "token 169 (летний) is not found\n",
      "\n",
      "712: _dataset/rucoref/rucoref_texts/lentaru/lentaru019.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 330 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 154121.41it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 14 sentences, 330 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 42955.56it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 330 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 330 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "713: _dataset/rucoref/rucoref_texts/lentaru/lentaru015.txt\n",
      "Load corpus\n",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 335 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 18/18 [00:00<00:00, 35848.75it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 18/18 [00:00<00:00, 76569.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 18 sentences, 335 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 335 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 335 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 34: Санкт-Петербурга != Санкт\n",
      "token 34: Санкт-Петербурга != Санкт\n",
      "token 39 (-) is not found\n",
      "token 39 (-) is not found\n",
      "token 40 (Петербурга) is not found\n",
      "token 40 (Петербурга) is not found\n",
      "token 34: Санкт-Петербурга != Санкт\n",
      "token 34: Санкт-Петербурга != Санкт\n",
      "token 39 (-) is not found\n",
      "token 39 (-) is not found\n",
      "token 40 (Петербурга) is not found\n",
      "token 40 (Петербурга) is not found\n",
      "token 34: Санкт-Петербурга != Санкт\n",
      "token 34: Санкт-Петербурга != Санкт\n",
      "token 39 (-) is not found\n",
      "token 39 (-) is not found\n",
      "token 40 (Петербурга) is not found\n",
      "token 40 (Петербурга) is not found\n",
      "token 198: Фонтанка != Фонтанка.ру\n",
      "token 198: Фонтанка != Фонтанка.ру\n",
      "token 979: Фонтанка != Фонтанка.ру\n",
      "token 979: Фонтанка != Фонтанка.ру\n",
      "\n",
      "714: _dataset/rucoref/rucoref_texts/lentaru/lentaru018.txt\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 243 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 11/11 [00:00<00:00, 27139.61it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 11/11 [00:00<00:00, 42327.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 11 sentences, 243 tokens\n",
      "Save corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 243 tokens\n",
      "Save corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 243 tokens\n",
      "Load corpus... done.\n",
      "Preprocess corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 20 sentences, 324 tokens\n",
      "Save corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 155: 59-летний != 59\n",
      "token 155: 59-летний != 59\n",
      "token 157 (-) is not found\n",
      "token 157 (-) is not found\n",
      "token 158 (летний) is not found\n",
      "token 158 (летний) is not found\n",
      "\n",
      "715: _dataset/rucoref/rucoref_texts/lentaru/lentaru006.txt\n",
      "Load corpus\n",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 324 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 30908.65it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 20/20 [00:00<00:00, 66841.50it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 324 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 20                                                           \n",
      "Corpus has been loaded: 20 sentences, 324 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "716: _dataset/rucoref/rucoref_texts/lentaru/lentaru007.txt\n",
      "Load corpus\n",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 294 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 44315.21it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 148239.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 17 sentences, 294 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 294 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 294 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 778: 25-летний != 25\n",
      "token 778: 25-летний != 25\n",
      "token 780 (-) is not found\n",
      "token 780 (-) is not found\n",
      "token 781 (летний) is not found\n",
      "token 781 (летний) is not found\n",
      "token 798: 19-летний != 19\n",
      "token 798: 19-летний != 19\n",
      "token 800 (-) is not found\n",
      "token 800 (-) is not found\n",
      "token 801 (летний) is not found\n",
      "token 801 (летний) is not found\n",
      "token 1292: 109-я != 109\n",
      "token 1292: 109-я != 109\n",
      "token 1295 (-) is not found\n",
      "token 1295 (-) is not found\n",
      "token 1296 (я) is not found\n",
      "token 1296 (я) is not found\n",
      "\n",
      "717: _dataset/rucoref/rucoref_texts/lentaru/lentaru010.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 273 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 41675.13it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 80549.05it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 14 sentences, 273 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 273 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 273 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 282: Чурюмова-Герасименко != Чурюмова\n",
      "token 282: Чурюмова-Герасименко != Чурюмова\n",
      "token 290 (-) is not found\n",
      "token 290 (-) is not found\n",
      "token 291 (Герасименко) is not found\n",
      "token 291 (Герасименко) is not found\n",
      "token 1330: Чурюмова-Герасименко != Чурюмова\n",
      "token 1330: Чурюмова-Герасименко != Чурюмова\n",
      "token 1338 (-) is not found\n",
      "token 1338 (-) is not found\n",
      "token 1339 (Герасименко) is not found\n",
      "token 1339 (Герасименко) is not found\n",
      "\n",
      "718: _dataset/rucoref/rucoref_texts/lentaru/lentaru014.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 360 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 129854.61it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 305410.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 19 paragraphs, 30 sentences, 360 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 360 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 360 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "719: _dataset/rucoref/rucoref_texts/lentaru/lentaru008.txt\n",
      "Load corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 217 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 13/13 [00:00<00:00, 23852.12it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 13/13 [00:00<00:00, 40691.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 13 sentences, 217 tokens\n",
      "Save corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 217 tokens\n",
      "Save corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 13                                                           \n",
      "Corpus has been loaded: 13 sentences, 217 tokens\n",
      "Load corpus... done.\n",
      "Preprocess corpus\n",
      "[> 0                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "720: _dataset/rucoref/rucoref_texts/lentaru/lentaru011.txt\n",
      "Load corpus\n",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 588 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 43812.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "[=] 30                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 30 sentences, 588 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 30/30 [00:00<00:00, 120989.54it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 588 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 30                                                           \n",
      "Corpus has been loaded: 30 sentences, 588 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 177: пресс-секретарь != пресс\n",
      "token 177: пресс-секретарь != пресс\n",
      "token 182 (-) is not found\n",
      "token 182 (-) is not found\n",
      "token 183 (секретарь) is not found\n",
      "token 183 (секретарь) is not found\n",
      "token 230 (@) is not found\n",
      "token 230 (@) is not found\n",
      "token 231: ссылка != durov\n",
      "token 231: ссылка != durov\n",
      "token 450: пресс-секретаря != пресс\n",
      "token 450: пресс-секретаря != пресс\n",
      "token 455 (-) is not found\n",
      "token 455 (-) is not found\n",
      "token 456 (секретаря) is not found\n",
      "token 456 (секретаря) is not found\n",
      "token 1381: пресс-секретаря != пресс\n",
      "token 1381: пресс-секретаря != пресс\n",
      "token 1386 (-) is not found\n",
      "token 1386 (-) is not found\n",
      "token 1387 (секретаря) is not found\n",
      "token 1387 (секретаря) is not found\n",
      "\n",
      "721: _dataset/rucoref/rucoref_texts/lentaru/lentaru012.txt\n",
      "Load corpus\n",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 328 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 18/18 [00:00<00:00, 86778.70it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 18/18 [00:00<00:00, 69840.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been processed: 1 documents, 5 paragraphs, 18 sentences, 328 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 328 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 328 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "722: _dataset/rucoref/rucoref_texts/lentaru/lentaru003.txt\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 234 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 11/11 [00:00<00:00, 36616.94it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 11/11 [00:00<00:00, 60152.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 11 sentences, 234 tokens\n",
      "Save corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 234 tokens\n",
      "Save corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 11                                                           \n",
      "Corpus has been loaded: 11 sentences, 234 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "723: _dataset/rucoref/rucoref_texts/lentaru/lentaru013.txt\n",
      "Load corpus\n",
      "[=] 8                                                            \n",
      "Corpus has been loaded: 8 sentences, 166 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 8                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 8 sentences, 166 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 8                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 15880.00it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 8/8 [00:00<00:00, 19097.57it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 8                                                           \n",
      "Corpus has been loaded: 8 sentences, 166 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 8                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 8                                                           \n",
      "Corpus has been loaded: 8 sentences, 166 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 886: этно-религиозного != этно\n",
      "token 886: этно-религиозного != этно\n",
      "token 890 (-) is not found\n",
      "token 890 (-) is not found\n",
      "token 891 (религиозного) is not found\n",
      "token 891 (религиозного) is not found\n",
      "\n",
      "724: _dataset/rucoref/rucoref_texts/lentaru/lentaru001.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 485 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 218660.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 9 paragraphs, 22 sentences, 485 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 124527.24it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 485 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 485 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "725: _dataset/rucoref/rucoref_texts/lentaru/lentaru002.txt\n",
      "Load corpus\n",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 346 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 43299.77it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 15/15 [00:00<00:00, 109607.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 15 sentences, 346 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 346 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 15                                                           \n",
      "Corpus has been loaded: 15 sentences, 346 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "726: _dataset/rucoref/rucoref_texts/lentaru/lentaru020.txt\n",
      "Load corpus\n",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 348 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 172646.90it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 17/17 [00:00<00:00, 116318.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been processed: 1 documents, 8 paragraphs, 17 sentences, 348 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 348 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 17                                                           \n",
      "Corpus has been loaded: 17 sentences, 348 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "727: _dataset/rucoref/rucoref_texts/lentaru/lentaru004.txt\n",
      "Load corpus\n",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 429 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 79891.50it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 22/22 [00:00<00:00, 89240.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 22 sentences, 429 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 429 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 22                                                           \n",
      "Corpus has been loaded: 22 sentences, 429 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 200: Kuk-ryol != Kuk\n",
      "token 200: Kuk-ryol != Kuk\n",
      "token 203 (-) is not found\n",
      "token 203 (-) is not found\n",
      "token 204 (ryol) is not found\n",
      "token 204 (ryol) is not found\n",
      "\n",
      "728: _dataset/rucoref/rucoref_texts/lentaru/lentaru017.txt\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 253 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 68042.01it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 14/14 [00:00<00:00, 146800.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been processed: 1 documents, 6 paragraphs, 14 sentences, 253 tokens\n",
      "Save corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 253 tokens\n",
      "Save corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "[=] 14                                                           \n",
      "Corpus has been loaded: 14 sentences, 253 tokens\n",
      "Load corpus... done.\n",
      "Preprocess corpus\n",
      "[=] 5                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 159: 26-летнее != 26\n",
      "token 159: 26-летнее != 26\n",
      "token 161 (-) is not found\n",
      "token 161 (-) is not found\n",
      "token 162 (летнее) is not found\n",
      "token 162 (летнее) is not found\n",
      "token 306: Лайси-Тауншипе != Лайси\n",
      "token 306: Лайси-Тауншипе != Лайси\n",
      "token 311 (-) is not found\n",
      "token 311 (-) is not found\n",
      "token 312 (Тауншипе) is not found\n",
      "token 312 (Тауншипе) is not found\n",
      "\n",
      "729: _dataset/rucoref/rucoref_texts/lentaru/lentaru009.txt\n",
      "Load corpus\n",
      "[=] 5                                                            \n",
      "Corpus has been loaded: 5 sentences, 121 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 5/5 [00:00<00:00, 43781.88it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Corpus has been processed: 1 documents, 3 paragraphs, 5 sentences, 121 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 5                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 5/5 [00:00<00:00, 21269.29it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 5                                                           \n",
      "Corpus has been loaded: 5 sentences, 121 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 5                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 5                                                           \n",
      "Corpus has been loaded: 5 sentences, 121 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "token 182: 89-летний != 89\n",
      "token 182: 89-летний != 89\n",
      "token 184 (-) is not found\n",
      "token 184 (-) is not found\n",
      "token 185 (летний) is not found\n",
      "token 185 (летний) is not found\n",
      "token 470: 13-миллионной != 13\n",
      "token 470: 13-миллионной != 13\n",
      "token 472 (-) is not found\n",
      "token 472 (-) is not found\n",
      "token 473 (миллионной) is not found\n",
      "token 473 (миллионной) is not found\n",
      "\n",
      "730: _dataset/rucoref/rucoref_texts/libru/kowalewskij.txt\n",
      "Load corpus\n",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 407 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 42208.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been processed: 1 documents, 11 paragraphs, 27 sentences, 407 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 27/27 [00:00<00:00, 176395.96it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 407 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 27                                                           \n",
      "Corpus has been loaded: 27 sentences, 407 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "731: _dataset/rucoref/rucoref_texts/libru/ermolaew2.txt\n",
      "Load corpus\n",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 411 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 18/18 [00:00<00:00, 21651.12it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 18/18 [00:00<00:00, 83979.39it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been processed: 1 documents, 8 paragraphs, 18 sentences, 411 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 411 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 18                                                           \n",
      "Corpus has been loaded: 18 sentences, 411 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "732: _dataset/rucoref/rucoref_texts/libru/ufo.txt\n",
      "Load corpus\n",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 701 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 128046.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been processed: 1 documents, 10 paragraphs, 41 sentences, 701 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 362034.66it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 701 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 701 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "733: _dataset/rucoref/rucoref_texts/libru/filippow.txt\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1005 tokens\n",
      "Processing corpus\n",
      "\r",
      "  0%|          | 0/103 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been processed: 1 documents, 26 paragraphs, 103 sentences, 1005 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 477.39it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 103/103 [00:00<00:00, 475.32it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1005 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[> 100                                                            \r",
      "[=] 103                                                           \n",
      "Corpus has been loaded: 103 sentences, 1005 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "734: _dataset/rucoref/rucoref_texts/libru/kolobkowa.txt\n",
      "Load corpus\n",
      "[=] 88                                                           \n",
      "Corpus has been loaded: 88 sentences, 744 tokens\n",
      "Processing corpus\n",
      "  0%|          | 0/88 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been processed: 1 documents, 28 paragraphs, 88 sentences, 744 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 88/88 [00:00<00:00, 418.15it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 88/88 [00:00<00:00, 401.17it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been loaded: 88 sentences, 744 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 88                                                           \n",
      "Corpus has been loaded: 88 sentences, 744 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "735: _dataset/rucoref/rucoref_texts/libru/lyalin2.txt\n",
      "Load corpus\n",
      "[=] 44                                                           \n",
      "Corpus has been loaded: 44 sentences, 517 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 44/44 [00:00<00:00, 343028.58it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been processed: 1 documents, 16 paragraphs, 44 sentences, 517 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 44/44 [00:00<00:00, 158683.90it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been loaded: 44 sentences, 517 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 44                                                           \n",
      "Corpus has been loaded: 44 sentences, 517 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "736: _dataset/rucoref/rucoref_texts/libru/boldyrewae.txt\n",
      "Load corpus\n",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 362 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 147168.56it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 16/16 [00:00<00:00, 169895.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been processed: 1 documents, 7 paragraphs, 16 sentences, 362 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 362 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 16                                                           \n",
      "Corpus has been loaded: 16 sentences, 362 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "737: _dataset/rucoref/rucoref_texts/libru/maslov.txt\n",
      "Load corpus\n",
      "[=] 29                                                           \n",
      "Corpus has been loaded: 29 sentences, 360 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 29/29 [00:00<00:00, 75083.22it/s]\n",
      "Processing corpus\n",
      "100%|██████████| 29/29 [00:00<00:00, 79292.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 29                                                           \n",
      "Corpus has been processed: 1 documents, 4 paragraphs, 29 sentences, 360 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 29                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 29                                                           \n",
      "Corpus has been loaded: 29 sentences, 360 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 29                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 29                                                           \n",
      "Corpus has been loaded: 29 sentences, 360 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "738: _dataset/rucoref/rucoref_texts/libru/ugrumowa.txt\n",
      "Load corpus\n",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 724 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 105371.61it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been processed: 1 documents, 12 paragraphs, 41 sentences, 724 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing corpus\n",
      "100%|██████████| 41/41 [00:00<00:00, 360516.70it/s]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 724 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 41                                                           \n",
      "Corpus has been loaded: 41 sentences, 724 tokens\n",
      "Load corpus... "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "token 37: Санкт-Петербург != Санкт\n",
      "token 37: Санкт-Петербург != Санкт\n",
      "token 42 (-) is not found\n",
      "token 42 (-) is not found\n",
      "token 43 (Петербург) is not found\n",
      "token 43 (Петербург) is not found\n",
      "token 1175: Санкт-Петербурге != Санкт\n",
      "token 1175: Санкт-Петербурге != Санкт\n",
      "token 1180 (-) is not found\n",
      "token 1180 (-) is not found\n",
      "token 1181 (Петербурге) is not found\n",
      "token 1181 (Петербурге) is not found\n",
      "token 2241: Санкт-Петербург != Санкт\n",
      "token 2241: Санкт-Петербург != Санкт\n",
      "token 2246 (-) is not found\n",
      "token 2246 (-) is not found\n",
      "token 2247 (Петербург) is not found\n",
      "token 2247 (Петербург) is not found\n",
      "\n",
      "739: _dataset/rucoref/rucoref_texts/libru/yaglov.txt\n",
      "Load corpus\n",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 519 tokens\n",
      "Processing corpus\n",
      "100%|██████████| 49/49 [00:00<00:00, 193887.64it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "done.\n",
      "Preprocess corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been processed: 1 documents, 26 paragraphs, 49 sentences, 519 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been saved\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus\n",
      "100%|██████████| 49/49 [00:00<00:00, 301350.29it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 519 tokens\n",
      "Save corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been saved\n",
      "Load corpus\n",
      "\r",
      "[> 0                                                             \r",
      "[=] 49                                                           \n",
      "Corpus has been loaded: 49 sentences, 519 tokens\n"
     ]
    }
   ],
   "source": [
    "with open(log_fn, 'wt', encoding='utf-8') as f_log:\n",
    "\n",
    "    def log(text=''):\n",
    "        print(text)\n",
    "        print(text, file=f_log)\n",
    "\n",
    "    out_fn = os.path.join(dataset_dir, 'out.conllu')\n",
    "    for doc_id in groups['doc_id'].unique():\n",
    "        in_fn, _ = get_fns(doc_id)\n",
    "        log('{}: {}'.format(doc_id, in_fn))\n",
    "\n",
    "        raw_corpus, raw_puncts = get_raw(in_fn)\n",
    "        if NEED_SHIFT_ADJUST:\n",
    "            adjust_raw_corpus(doc_id, raw_corpus)\n",
    "            adjust_raw_corpus(doc_id, raw_puncts)\n",
    "\n",
    "        tp.clear_corpus()\n",
    "        tp.load_pars(in_fn, eop=r'\\n')\n",
    "        tp.do_all(tag_date=False, norm_punct=True)\n",
    "        tp.save(out_fn + '$')\n",
    "\n",
    "        tagger_f.predict(tagger_u.predict(out_fn + '$'), save_to=out_fn)\n",
    "\n",
    "        corpus_orig = list(Conllu.load(out_fn))\n",
    "        corpus = []\n",
    "        make_corpus()\n",
    "        validate_corpus()\n",
    "        process_corpus(corpus, raw_corpus)\n",
    "        process_puncts(corpus, raw_puncts)\n",
    "        Conllu.save(corpus_orig, out_fn)\n",
    "        corpus = list(Conllu.load(out_fn))\n",
    "\n",
    "        shifts = {}\n",
    "        for sent in corpus:\n",
    "            for tok in sent[0]:\n",
    "                form, shift = tok['FORM'] or '', tok['MISC'].get('Shift', '')\n",
    "                if shift:\n",
    "                    shifts[shift] = norm_punct(form)\n",
    "        for tks, tk_shifts in groups[groups['doc_id'] == doc_id][['content', 'tk_shifts']].values:\n",
    "            tks = tks.split()\n",
    "            tk_shifts = tk_shifts.split(',')\n",
    "            assert len(tks) == len(tk_shifts), \\\n",
    "                'len({}) != len({})'.format(tks, tk_shifts)\n",
    "            for tk, tk_shift in zip(tks, tk_shifts):\n",
    "                tok = shifts.get(tk_shift)\n",
    "                if tok is None:\n",
    "                    print('token {} ({}) is not found'.format(tk_shift, tk))\n",
    "                    log('token {} ({}) is not found'.format(tk_shift, tk))\n",
    "                elif norm_punct(tok) != norm_punct(tk):\n",
    "                    print('token {}: {} != {}'.format(tk_shift, tok, tk))\n",
    "                    log('token {}: {} != {}'.format(tk_shift, tok, tk))\n",
    "        log()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
